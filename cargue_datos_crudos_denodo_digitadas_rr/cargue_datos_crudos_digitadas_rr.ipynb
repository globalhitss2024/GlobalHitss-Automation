{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20fa1dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n***************************************************************************************\\n* CLARO  HITSS - EMPRESAS Y NEGOCIOS                                                  *\\n* OBJETIVO: Extración de fuentes crudas de digitadas RR                               * \\n*           y cargue a base de datos de forma automatica                              *\\n*           Comunicacion Celular S.A.- Comcel S.A\\\\Wilmer Camargo Ochoa - Data_PCC     *\\n* TABLA DE INGESTA POSTGRESQL: tb_datos_crudos_denodo_digitadas_rr                            *\\n* FECHA CREACION: 05 de Septiembre de 2024                                            *\\n* ELABORADO POR: LAURA GAITAN                                                         *\\n* *************************************************************************************\\n* MODIFICACIONES\\n* NOMBRE                   FECHA      VERSION            DESCRIPCION\\n* \\n*\\n***************************************************************************************\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "***************************************************************************************\n",
    "* CLARO  HITSS - EMPRESAS Y NEGOCIOS                                                  *\n",
    "* OBJETIVO: Extración de fuentes crudas de digitadas RR                               * \n",
    "*           y cargue a base de datos de forma automatica                              *\n",
    "*           Comunicacion Celular S.A.- Comcel S.A\\Wilmer Camargo Ochoa - Data_PCC     *\n",
    "* TABLA DE INGESTA POSTGRESQL: tb_datos_crudos_denodo_digitadas_rr                            *\n",
    "* FECHA CREACION: 05 de Septiembre de 2024                                            *\n",
    "* ELABORADO POR: LAURA GAITAN                                                         *\n",
    "* *************************************************************************************\n",
    "* MODIFICACIONES\n",
    "* NOMBRE                   FECHA      VERSION            DESCRIPCION\n",
    "* \n",
    "*\n",
    "***************************************************************************************\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e1597ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib3\n",
    "urllib3.disable_warnings()\n",
    "from datetime import datetime\n",
    "import pyodbc\n",
    "import sys\n",
    "#sys.path.append('C:/Users/46122499/Documents/ambiente_desarrollo/dev-empresas-negocios-env/desarrollo_notebook')\n",
    "#sys.path.append('C:/ambiente_desarrollo/dev-empresas-negocios-env/desarrollo_produccion')\n",
    "sys.path.append('C:/ambiente_desarrollo/dev-empresas-negocios-env/desarrollo_notebook')\n",
    "import parametros_desarrollo as par\n",
    "import uuid\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "import os\n",
    "import psycopg2\n",
    "import logging\n",
    "import pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37db7930",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#VARIABLES GLOBALES\n",
    "fecha_inicio = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "fecha_actual = datetime.today().date()\n",
    "duracion = []\n",
    "fuentes = []\n",
    "cantidad_registros = []\n",
    "destino = ['tb_datos_crudos_denodo_digitadas_rr']\n",
    "estado = []\n",
    "funcion_error = []\n",
    "descripcion_error = []\n",
    "id_ejecucion_en_curso = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb214086",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def salidaLogMonitoreo():\n",
    "    \n",
    "    Este metodo captura la informacion que se desea imprimir en el Log\n",
    "    para monitoreo y funcionamiento del desarrollo\n",
    "    Argumentos:\n",
    "        None\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        None\n",
    "    \n",
    "    Fecha_fin = datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "    print(f\"Fecha_inicio: {fecha_inicio}\")\n",
    "    print(f\"Fecha_fin: {Fecha_fin}\")\n",
    "    print(f\"Duracion: {duracion}\")\n",
    "    print(f\"Fuentes: {fuentes}\")\n",
    "    print(f\"Cantidad_registros: {cantidad_registros}\")\n",
    "    print(f\"Destino: {destino}\")\n",
    "    print(f\"Estado: {estado}\")\n",
    "    print(\"Lugar errores: \", ' | '.join(map(str, funcion_error)))\n",
    "    print(\"Descripción errores: \", ' | '.join(map(str, descripcion_error)))\n",
    "    if estado[0] == 1 :\n",
    "        print(\"Ejecución exitosa\")\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "\n",
    "\"\"\"\n",
    "def salidaLogMonitoreo():\n",
    "    \"\"\"\n",
    "    Este método captura la información que se desea imprimir en el Log\n",
    "    para monitoreo y funcionamiento del desarrollo.\n",
    "    \"\"\"\n",
    "    Fecha_fin = datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "    logging.info(f\"Fecha_inicio: {fecha_inicio}\")\n",
    "    logging.info(f\"Fecha_fin: {Fecha_fin}\")\n",
    "    logging.info(f\"Duracion: {duracion}\")\n",
    "    logging.info(f\"Fuentes: {fuentes}\")\n",
    "    logging.info(f\"Cantidad_registros: {cantidad_registros}\")\n",
    "    logging.info(f\"Destino: {destino}\")\n",
    "    logging.info(f\"Estado: {estado}\")\n",
    "    logging.info(\"Lugar errores: \" + ' | '.join(map(str, funcion_error)))\n",
    "    logging.info(\"Descripción errores: \" + ' | '.join(map(str, descripcion_error)))\n",
    "    if estado[0] == 1:\n",
    "        logging.info(\"Ejecución exitosa\")\n",
    "    logging.info(\"------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed076c09",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def cargueResumen(id_ejecucion, fecha_inicio_date,fuentes,cantidad_registros,destino,estado):\n",
    "    \"\"\"\n",
    "    Función que se encarga de cargar estadisticas de los datos que estan siendo procesados\n",
    "    \n",
    "    Argumentos:\n",
    "        id_ejecucion: Contiene un numero alfanumerico para creación de llaves primarias y foraneas de la base de datos\n",
    "        fecha_inicio_date: Fecha de inicio del procesamiento\n",
    "        fecha_fin_date: Fecha de fin del procesamiento\n",
    "        duracion_proceso: Duración del procesamiento \n",
    "        fuentes: Fuentes de donde provienen los datos\n",
    "        cantidad_registros: Cantidad de registros procesados\n",
    "        destino: Tabla donde se ingestan los datos\n",
    "        estado: Indica el estado del proceso de acuerdo a lo definido en la base de datos en la tabla control_procesamiento.estados_cargue \n",
    "        \n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        SQLAlchemyError as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        \n",
    "        df_resumen_cargue = pd.DataFrame({\n",
    "            'id_ejecucion': id_ejecucion,\n",
    "            'fecha_inicio_procesamiento': fecha_inicio_date,\n",
    "            'fuentes': fuentes,\n",
    "            'cantidad_registros': cantidad_registros,\n",
    "            'destino': [destino],\n",
    "            'id_estado': [estado],\n",
    "        })\n",
    "\n",
    "        conexion = create_engine(f'postgresql://{par.usuario}:{par.contrasena}@{par.host}:{par.port}/{par.bd_inteligencia_comercial}')\n",
    "        # Especificar el esquema y la tabla en la que deseas insertar los datos\n",
    "        nombre_esquema = 'control_procesamiento'\n",
    "        nombre_tabla = 'tb_resumen_cargue'\n",
    "        df_resumen_cargue.to_csv('data_pruebas.csv',index=False,mode='w')\n",
    "        df_resumen_cargue.to_sql(nombre_tabla, con=conexion, schema=nombre_esquema, if_exists='append', index=False)\n",
    "\n",
    "\n",
    "    except SQLAlchemyError as e:\n",
    "        fuentes.append('db_dwh_corporativo.ventas.extract_rr_ventas_dig')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(cargueResumen.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        salidaLogMonitoreo()\n",
    "    finally:\n",
    "        conexion.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ce11313",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def insertarErroresDB():\n",
    "    \"\"\"\n",
    "    Metodo para insertar a POSTGRESQL los errores capturados durante la ejecución\n",
    "    Argumentos Globales:\n",
    "        fecha_inicio: Captura la fecha en que inicio la ejecución\n",
    "        fecha_fin: Captura la fecha en que finalizo la ejecución\n",
    "        duracion: Duración del procesamiento\n",
    "        fuente: Indica la fuente de donde provienen los datos\n",
    "        cantidad_registros: Cantidad de registros por fuente\n",
    "        destino: Indica la tabla a donde se estan ingestando los datos\n",
    "        id_estado: Indica el estado del proceso definidos en la base de datos \n",
    "        funcion_error: Indica la función donde se esta presentando una falla\n",
    "        descripcion_error: Descripción del error generado\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        SQLAlchemyError as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convertir las cadenas de texto a objetos datetime\n",
    "        fecha_inicio_tr = datetime.strptime(fecha_inicio, \"%Y-%m-%d %H:%M:%S\")\n",
    "        fecha_fin = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        fecha_fin_tr = datetime.strptime(fecha_fin, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        duracion_proceso_timedelta = fecha_fin_tr - fecha_inicio_tr\n",
    "        duracion_proceso_seconds = duracion_proceso_timedelta.total_seconds()\n",
    "        \n",
    "        errores = pd.DataFrame({\n",
    "            'fecha_inicio': fecha_inicio,\n",
    "            'fecha_fin': fecha_fin,\n",
    "            'duracion': duracion_proceso_seconds,\n",
    "            'fuente': fuentes,\n",
    "            'cantidad_registros': cantidad_registros,\n",
    "            'destino': destino,\n",
    "            'id_estado': estado,\n",
    "            'funcion_error': funcion_error,\n",
    "            'descripcion_error': descripcion_error\n",
    "        })\n",
    "        \n",
    "        conexion_errores = create_engine(f'postgresql://{par.usuario}:{par.contrasena}@{par.host}:{par.port}/{par.bd_inteligencia_comercial}')\n",
    "        # Especificar el esquema y la tabla en la que deseas insertar los datos\n",
    "        nombre_esquema = 'control_procesamiento'\n",
    "        nombre_tabla = 'tb_errores_cargue'\n",
    "        errores.to_sql(nombre_tabla, con=conexion_errores, schema=nombre_esquema, if_exists='append', index=False)\n",
    "        cargueResumen(id_ejecucion_en_curso, fecha_inicio_tr,'db_dwh_corporativo.ventas.extract_rr_ventas_dig',0,par.destino_macrofo,2) \n",
    "        salidaLogMonitoreo()\n",
    "\n",
    "    \n",
    "    except SQLAlchemyError as e:\n",
    "        fuentes.append('db_dwh_corporativo.ventas.extract_rr_ventas_dig')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(insertarErroresDB.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        salidaLogMonitoreo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7c8b7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conexion_BD():\n",
    "    \"\"\"\n",
    "    Función que genera la conexión hacia la base de datos por medio de la libreria psycopg2\n",
    "    \n",
    "    Argumentos:\n",
    "        id_ejecucion: id del proceso ejecutado\n",
    "        fecha_fin_date: Fecha fin de procesamiento\n",
    "        duracion_proceso_seg: Duración en segundos del procesamiento\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        Exception as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "        conn = psycopg2.connect(\n",
    "            host=par.host,\n",
    "            database=par.bd_inteligencia_comercial,\n",
    "            user=par.usuario,\n",
    "            password=par.contrasena\n",
    "        )\n",
    "        return conn\n",
    "\n",
    "    except SQLAlchemyError as e:\n",
    "        fuentes.append('db_dwh_corporativo.ventas.extract_rr_ventas_dig')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(conexion_BD.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        salidaLogMonitoreo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad433359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conexionDenodoOdbc():\n",
    "    \"\"\"\n",
    "    Función que genera la conexión hacia la base de datos por medio de la libreria psycopg2\n",
    "    \n",
    "    Argumentos:\n",
    "        id_ejecucion: id del proceso ejecutado\n",
    "        fecha_fin_date: Fecha fin de procesamiento\n",
    "        duracion_proceso_seg: Duración en segundos del procesamiento\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        Exception as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "    try:\n",
    "        usuario_denodo=par.usuario_denodo\n",
    "        contraseña_denodo=par.contraseña_denodo\n",
    "        cadena=f'DSN=DenodoODBC;UID={usuario_denodo};PWD={contraseña_denodo}'\n",
    "        conn = pyodbc.connect(cadena)\n",
    "        return conn\n",
    "\n",
    "    except SQLAlchemyError as e:\n",
    "        fuentes.append('db_dwh_corporativo.ventas.extract_rr_ventas_dig')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(conexion_BD.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        salidaLogMonitoreo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6c43693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conexionOracleEndecapr():\n",
    "    \"\"\"\n",
    "    Función que genera la conexión hacia la base de datos por medio de la libreria psycopg2\n",
    "    \n",
    "    Argumentos:\n",
    "        id_ejecucion: id del proceso ejecutado\n",
    "        fecha_fin_date: Fecha fin de procesamiento\n",
    "        duracion_proceso_seg: Duración en segundos del procesamiento\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        Exception as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "    try:\n",
    "        usuario_denodo=par.usuario_denodo\n",
    "        contraseña_denodo=par.contraseña_denodo\n",
    "        cadena=f'DSN=DenodoODBC;UID={usuario_denodo};PWD={contraseña_denodo}'\n",
    "        conn = pyodbc.connect(cadena)\n",
    "        return conn\n",
    "\n",
    "    except SQLAlchemyError as e:\n",
    "        fuentes.append('db_dwh_corporativo.ventas.extract_rr_ventas_dig')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(conexion_BD.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        salidaLogMonitoreo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "49c70e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ejecutarConsultaOdbc():\n",
    "    \"\"\"\n",
    "    Método para ejecutar una consulta y devolver los resultados en un DataFrame.\n",
    "    \"\"\"\n",
    "    conn = conexionDenodoOdbc()\n",
    "    \n",
    "    try:\n",
    "        #cur = conn.cursor()\n",
    "        query = \"SELECT * FROM db_dwh_corporativo.extract_rr_ventas_dig WHERE aumento != 0\"\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(query)\n",
    "        rows = cursor.fetchall()\n",
    "        df = pd.DataFrame.from_records(rows, columns=[desc[0] for desc in cursor.description])\n",
    "\n",
    "        print (f'cantidad de registros descargados para digitadas rr: {df.shape[0]}')\n",
    "        df_resultado = df\n",
    "        \n",
    "        return df_resultado\n",
    "    \n",
    "    except pyodbc.Error as e:\n",
    "        if 1 in estado:\n",
    "            estado.remove(1)\n",
    "        if 2 not in estado:\n",
    "            estado.append(2)\n",
    "        cantidad_registros.append(0)\n",
    "        funcion_error.append(ejecutarConsultaOdbc.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        insertarErroresDB()\n",
    "        salidaLogMonitoreo()\n",
    "        return None\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "167a5c24",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def actualizarFechaFinProcesamiento(id_ejecucion, fecha_fin_date, duracion_proceso_seg):\n",
    "\n",
    "    \"\"\"\n",
    "    Función que actualiza la fecha fin de procesamiento y duración para el proceso que se ejecuto.\n",
    "    Utilizando cursores\n",
    "    \n",
    "    Argumentos:\n",
    "        id_ejecucion: id del proceso ejecutado\n",
    "        fecha_fin_date: Fecha fin de procesamiento\n",
    "        duracion_proceso_seg: Duración en segundos del procesamiento\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        Exception as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "        conn = conexion_BD()\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        update_query = \"\"\"\n",
    "            UPDATE control_procesamiento.tb_resumen_cargue \n",
    "            SET fecha_fin_procesamiento = %s,\n",
    "            duracion_segundos = %s\n",
    "            WHERE id_ejecucion = %s\n",
    "        \"\"\"\n",
    "        cur.execute(update_query, (fecha_fin_date, duracion_proceso_seg, id_ejecucion))\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        fuentes.append('db_dwh_corporativo.ventas.extract_rr_ventas_dig')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(actualizarFechaFinProcesamiento.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        insertarErroresDB()\n",
    "        salidaLogMonitoreo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "67193634",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def generate_uuid():\n",
    "    \"\"\"\n",
    "    Función que genera un numero alfanumerico para creación de llaves primarias y foraneas\n",
    "    \n",
    "    Argumentos:\n",
    "        None\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        Exception as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        return str(uuid.uuid4())\n",
    "    \n",
    "    except Exception as e:\n",
    "        fuentes.append('db_dwh_corporativo.ventas.extract_rr_ventas_dig')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(generate_uuid.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        insertarErroresDB()\n",
    "        salidaLogMonitoreo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "203288bf",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def configurarLogging():\n",
    "    \"\"\"\n",
    "    Configura el logging para escribir en un archivo y en la salida estándar\n",
    "    Utiliza la ruta definida en par.ruta_log para el directorio de logs.\n",
    "    \n",
    "    Argumentos:\n",
    "        None\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        None\n",
    "    \"\"\"\n",
    "    # Configuración del logging\n",
    "    log_directory = par.ruta_log  # Usa la ruta definida en config.py\n",
    "    log_file = os.path.join(log_directory, \"tb_datos_crudos_denodo_digitadas_rr.log\")\n",
    "\n",
    "    # Crear el directorio si no existe\n",
    "    if not os.path.exists(log_directory):\n",
    "        os.makedirs(log_directory)\n",
    "\n",
    "    # Configurar el logger\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file, mode='a'),  # 'a' para modo append\n",
    "            #logging.StreamHandler()  # Para imprimir en pantalla\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "265a6bf7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def cargueDatosBD(df_final):\n",
    "    \"\"\"\n",
    "    Función que se encarga de cargar los dataframes procesados hacia la base de datos\n",
    "    \n",
    "    Argumentos:\n",
    "        df_final: Contiene el dataframe que se requiere cargar a la BD\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        SQLAlchemyError as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "        conexion = create_engine(f'postgresql://{par.usuario}:{par.contrasena}@{par.host}:{par.port}/{par.bd_inteligencia_comercial}')\n",
    "        # Especificar el esquema y la tabla en la que deseas insertar los datos\n",
    "        nombre_esquema = 'fuentes_cruda'\n",
    "        nombre_tabla = 'tb_datos_crudos_denodo_digitadas_rr'\n",
    "        #print('cargando datos en base de datos principal')\n",
    "        df_final.to_csv('data_base.csv',encoding='utf-8',index=False,mode='w')\n",
    "        df_final.to_sql(nombre_tabla, con=conexion, schema=nombre_esquema, if_exists='append', index=False)\n",
    "       \n",
    "        \n",
    "    except SQLAlchemyError as e:\n",
    "        fuentes.append('db_dwh_corporativo.ventas.extract_rr_ventas_dig')\n",
    "        cantidad_registros.append(0)\n",
    "        if 1 in estado:\n",
    "            estado.remove(1)\n",
    "        if 2 not in estado:\n",
    "            estado.append(2)\n",
    "        funcion_error.append(cargueDatosBD.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        insertarErroresDB()\n",
    "        salidaLogMonitoreo()\n",
    "    finally:\n",
    "        conexion.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0022e97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConsultarIformacionAlmacenada(tabla_consulta):\n",
    "    \"\"\"\n",
    "    Función que consulta los datos historicos existentes en la base de datos de la tabla\n",
    "    \n",
    "    Argumentos:\n",
    "        None\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        Exception as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "    try:\n",
    "    \n",
    "        \n",
    "        engine = conexion_BD()\n",
    "        sql_consulta = f\"SELECT * FROM fuentes_cruda.{tabla_consulta}\"\n",
    "\n",
    "        df_tabla_bd = pd.read_sql(sql_consulta, engine)\n",
    "\n",
    "        return df_tabla_bd\n",
    "     \n",
    "       \n",
    "    except Exception as e:\n",
    "        fuentes.append('db_dwh_corporativo.extract_rr_ventas_dig')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(ConsultarIformacionAlmacenada.__name__)\n",
    "        descripcion_error.append(str(e))\n",
    "        insertarErroresDB()\n",
    "        salidaLogMonitoreo()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "10bc68f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seleccionCamposdigitadasrr(df,fecha_inicio_date, id_ejecucion):\n",
    "    \"\"\"\n",
    "    Función encargada de seleccionar los datos relevantes de la base de datos de digitadas RR, \n",
    "    extraídos desde Denodo, y generar campos adicionales necesarios para el control \n",
    "    y procesamiento de los datos.\n",
    "\n",
    "    Argumentos:\n",
    "        df: DataFrame que contiene los datos de digitadas RR a procesar, extraídos de Denodo.\n",
    "        fecha_inicio_date: Fecha y hora en que comienza el procesamiento de los datos.\n",
    "        id_ejecucion: Identificador único de la ejecución, utilizado para la creación de claves primarias y foráneas en la base de datos.\n",
    "    \n",
    "    Retorna: \n",
    "        df_selected: DataFrame final con los datos seleccionados y enriquecidos, listo para ser insertado en la tabla de destino.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        df_base = df.copy()\n",
    "\n",
    "        df_base.rename(columns={\n",
    "            'vdicta': 'id_cuenta',\n",
    "            'vdiort': 'ot_orden_trabajo',\n",
    "            'vdinom': 'nombre',\n",
    "            'vditid': 'tipo_documento',\n",
    "            'vdinid': 'numero_documento',\n",
    "            'vdite1': 'numero_telefono_1',\n",
    "            'vdite2': 'numero_telefono_2',\n",
    "            'vdical': 'calle',\n",
    "            'vdidir': 'direccion_residencia',\n",
    "            'vdiapt': 'numero_apartamento',\n",
    "            'vdiccd': 'ciudad_venta',\n",
    "            'vdicdi': 'codigo_division',\n",
    "            'vdityp': 'tipo_suscriptor',\n",
    "            'vdiest': 'estado',\n",
    "            'vditar': 'tarifa',\n",
    "            'vdicse': 'codigo_servicio',\n",
    "            'vdinse': 'nombre_servicio',\n",
    "            'vdidse': 'descripcion_servicio',\n",
    "            'vdinas': 'numero_dealer',\n",
    "            'vdinod': 'nodo',\n",
    "            'vdinno': 'nombre_nodo',\n",
    "            'vdiusu': 'wo_creador',\n",
    "            'vdifcc': 'fecha_creacion_inicio_anio',\n",
    "            'vdifcy': 'fecha_creacion_fin_anio',\n",
    "            'vdifcm': 'fecha_creacion_mes',\n",
    "            'vdifcd': 'fecha_creacion_dia',\n",
    "            'vdifco': 'fecha_creacion',\n",
    "            'vditvt': 'tipo_venta',\n",
    "            'vdidis': 'val_dif_service',\n",
    "            'vdirme': 'valor_servicio',\n",
    "            'vdirma': 'renta_wo_anterior',\n",
    "            'vdirmc': 'renta_wo_actual',\n",
    "            'vdirmd': 'diferencia_renta',\n",
    "            'vdinli': 'numero_lineas_suscriptor',\n",
    "            'vdinus': 'numero_servicios',\n",
    "            'vdiori': 'origen_datos',\n",
    "            'vdinf1': 'email_2',\n",
    "            'vdfchp': 'fecha_permanencia',\n",
    "            'vdtpro': 'segmento',\n",
    "            'vdtnes': 'especialista',\n",
    "            'vdtarg': 'area_gcia_vtas',\n",
    "            'vdtcan': 'canal',\n",
    "            'vdtgvd': 'aliado',\n",
    "            'vdtpob': 'poblacion',\n",
    "            'vdtarv': 'area_venta',\n",
    "            'vdtzng': 'zona_gcia_vtas',\n",
    "            'vdtznv': 'zona_venta',\n",
    "            'vdemfa': 'email_uno',\n",
    "            'vdinoc': 'conyugue',\n",
    "            'vdprbf': 'cod_black_list',\n",
    "            'vdprbn': 'desc_black_list',\n",
    "            'tipo_linea': 'tipo_red',\n",
    "            'aumento': 'aumento',\n",
    "            'vdiase': 'nombre_dealer',\n",
    "            'vdicoo': 'coordinador',\n",
    "            'vdirtt': 'hora_creacion'\n",
    "        }, inplace=True)\n",
    "\n",
    "\n",
    "        df_historico = ConsultarIformacionAlmacenada('tb_datos_crudos_denodo_digitadas_rr')\n",
    "\n",
    "        df_base['llave_compuesta'] = (\n",
    "        df_base['id_cuenta'].astype(str) + '-' +\n",
    "        df_base['ot_orden_trabajo'].fillna('').astype(str) + '-' +\n",
    "        df_base['codigo_servicio'].fillna('').astype(str))\n",
    "        \n",
    "        df_historico['ot_orden_trabajo'] = df_historico ['ot_orden_trabajo'].apply(lambda x: int(x))\n",
    "        df_historico['id_cuenta'] = df_historico ['id_cuenta'].apply(lambda x: int(x))\n",
    "        \n",
    "        df_historico['llave_compuesta'] = (\n",
    "        df_historico['id_cuenta'].astype(str) + '-' +\n",
    "        df_historico['ot_orden_trabajo'].fillna('').astype(str) + '-' +\n",
    "        df_historico['codigo_servicio'].fillna('').astype(str))\n",
    "\n",
    "        \n",
    "        \n",
    "        df_merged = pd.merge(df_base, df_historico[['llave_compuesta']], on='llave_compuesta', how='outer', indicator=True)\n",
    "        df_nuevos = df_merged[df_merged['_merge'] == 'left_only'].copy()\n",
    "        df_nuevos.drop(columns=['_merge'], inplace=True)\n",
    "        df_nuevos.drop(columns=['llave_compuesta'], inplace=True)\n",
    "\n",
    "        df_nuevos = pd.concat([df_nuevos], ignore_index=True)\n",
    "\n",
    "        # Agregar las columnas necesarias\n",
    "        df_nuevos['id'] = [generate_uuid().upper() for _ in range(len(df_nuevos))]\n",
    "        df_nuevos['id_ejecucion'] = id_ejecucion\n",
    "        df_nuevos['fecha_procesamiento'] = pd.to_datetime(fecha_inicio_date)\n",
    "        df_nuevos['fuente'] = 'extract_rr_ventas_dig'\n",
    "        df_nuevos['id_estado'] = 1\n",
    "        df_nuevos = df_nuevos[~df_nuevos['tipo_venta'].str.contains('\\*\\*', na=False)]\n",
    "        df_nuevos['origen_datos'] = df_nuevos['origen_datos'].str.upper()\n",
    "        df_nuevos['conyugue'] = df_nuevos['conyugue'].str.upper()\n",
    "        df_nuevos['poblacion'] = df_nuevos['poblacion'].str.upper()\n",
    "        df_nuevos['vdinf2'] = df_nuevos['vdinf2'].str.replace('.', '', regex=False)\n",
    "\n",
    "        \n",
    "        \n",
    "        df_nuevos = df_nuevos[[\n",
    "            'id', 'id_ejecucion', 'ot_orden_trabajo', 'id_cuenta', 'nombre', 'tipo_documento', 'numero_documento', 'numero_telefono_1', \n",
    "            'numero_telefono_2', 'calle', 'direccion_residencia', 'numero_apartamento', 'ciudad_venta', 'codigo_division', 'tipo_suscriptor', \n",
    "            'estado', 'tarifa', 'codigo_servicio', 'nombre_servicio', 'nombre_dealer', 'coordinador', 'vdigas', \n",
    "            'vditse', 'vdiknd', 'vdirse', 'nodo', 'nombre_nodo', 'wo_creador', 'fecha_creacion_inicio_anio','vdieto','zona_gcia_vtas',\n",
    "            'fecha_creacion_fin_anio', 'fecha_creacion_mes', 'fecha_creacion_dia', 'fecha_creacion', 'tipo_venta',\n",
    "            'renta_wo_anterior', 'valor_servicio', 'hora_creacion', 'numero_lineas_suscriptor', 'val_dif_service',\n",
    "            'numero_servicios', 'origen_datos', 'vdica1', 'vdica2', 'vdica3', 'vdimig', 'conyugue', 'numero_dealer','renta_wo_actual',\n",
    "            'cod_black_list', 'desc_black_list', 'email_uno', 'email_2', 'fecha_permanencia', 'descripcion_servicio',\n",
    "            'segmento', 'especialista', 'area_gcia_vtas', 'canal', 'aliado', 'poblacion', 'vdinf2','diferencia_renta',\n",
    "            'area_venta', 'zona_venta', 'fecha_sys', 'tipo_red', 'aumento', 'fecha_procesamiento', 'fuente', 'id_estado'\n",
    "        ]]\n",
    "        \n",
    "        \n",
    "        return df_nuevos\n",
    "\n",
    "    \n",
    "    except Exception as e:\n",
    "        fuentes.append('db_dwh_corporativo.extract_rr_ventas_dig')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(seleccionCamposdigitadasrr.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        insertarErroresDB()\n",
    "        salidaLogMonitoreo()\n",
    "        raise e  # Re-raise the exception to handle it outside the function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8d03b84d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m fecha_inicio_date \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mstrptime(fecha_inicio, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m df_resultado_digitadas_rr \u001b[38;5;241m=\u001b[39m \u001b[43mejecutarConsultaOdbc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df_resultado_digitadas_rr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[44], line 5\u001b[0m, in \u001b[0;36mejecutarConsultaOdbc\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mMétodo para ejecutar una consulta y devolver los resultados en un DataFrame.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[43mconexionDenodoOdbc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m#cur = conn.cursor()\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[42], line 18\u001b[0m, in \u001b[0;36mconexionDenodoOdbc\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m cadena\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDSN=DenodoODBC;UID=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00musuario_denodo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m;PWD=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontraseña_denodo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 18\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[43mpyodbc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcadena\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[1;31mOperationalError\u001b[0m: ('08001', '[08001] ERROR:  authentication error: The username or password is incorrect\\nDETAIL:  java.sql.SQLException: authentication error: The username or password is incorrect\\n (101) (SQLDriverConnect)')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotNullViolation\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ambiente_desarrollo\\dev-empresas-negocios-env\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1967\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1967\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1968\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1969\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[1;32mc:\\ambiente_desarrollo\\dev-empresas-negocios-env\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:924\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 924\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mNotNullViolation\u001b[0m: el valor nulo en la columna «id_ejecucion» de la relación «tb_resumen_cargue» viola la restricción de no nulo\nDETAIL:  La fila que falla contiene (null, 2025-02-07 10:33:50, null, null, db_dwh_corporativo.ventas.extract_rr_ventas_dig, 0, tb_datos_crudos_fibra_optica, 2).\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 37\u001b[0m, in \u001b[0;36mcargueResumen\u001b[1;34m(id_ejecucion, fecha_inicio_date, fuentes, cantidad_registros, destino, estado)\u001b[0m\n\u001b[0;32m     36\u001b[0m     df_resumen_cargue\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_pruebas.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m     \u001b[43mdf_resumen_cargue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnombre_tabla\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconexion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnombre_esquema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mappend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SQLAlchemyError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\ambiente_desarrollo\\dev-empresas-negocios-env\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ambiente_desarrollo\\dev-empresas-negocios-env\\Lib\\site-packages\\pandas\\core\\generic.py:3087\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   3085\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[1;32m-> 3087\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3088\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3090\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3098\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ambiente_desarrollo\\dev-empresas-negocios-env\\Lib\\site-packages\\pandas\\io\\sql.py:842\u001b[0m, in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con, schema\u001b[38;5;241m=\u001b[39mschema, need_transaction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[1;32m--> 842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ambiente_desarrollo\\dev-empresas-negocios-env\\Lib\\site-packages\\pandas\\io\\sql.py:2018\u001b[0m, in \u001b[0;36mSQLDatabase.to_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m   2008\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_table(\n\u001b[0;32m   2009\u001b[0m     frame\u001b[38;5;241m=\u001b[39mframe,\n\u001b[0;32m   2010\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2015\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   2016\u001b[0m )\n\u001b[1;32m-> 2018\u001b[0m total_inserted \u001b[38;5;241m=\u001b[39m \u001b[43msql_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert_records\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2020\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2021\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2022\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2027\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2028\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2030\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_case_sensitive(name\u001b[38;5;241m=\u001b[39mname, schema\u001b[38;5;241m=\u001b[39mschema)\n",
      "File \u001b[1;32mc:\\ambiente_desarrollo\\dev-empresas-negocios-env\\Lib\\site-packages\\pandas\\io\\sql.py:1567\u001b[0m, in \u001b[0;36mSQLAlchemyEngine.insert_records\u001b[1;34m(self, table, con, frame, name, index, schema, chunksize, method, **engine_kwargs)\u001b[0m\n\u001b[0;32m   1566\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf cannot be used with MySQL\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m-> 1567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "File \u001b[1;32mc:\\ambiente_desarrollo\\dev-empresas-negocios-env\\Lib\\site-packages\\pandas\\io\\sql.py:1558\u001b[0m, in \u001b[0;36mSQLAlchemyEngine.insert_records\u001b[1;34m(self, table, con, frame, name, index, schema, chunksize, method, **engine_kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mStatementError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1560\u001b[0m     \u001b[38;5;66;03m# GH34431\u001b[39;00m\n\u001b[0;32m   1561\u001b[0m     \u001b[38;5;66;03m# https://stackoverflow.com/a/67358288/6067848\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ambiente_desarrollo\\dev-empresas-negocios-env\\Lib\\site-packages\\pandas\\io\\sql.py:1119\u001b[0m, in \u001b[0;36mSQLTable.insert\u001b[1;34m(self, chunksize, method)\u001b[0m\n\u001b[0;32m   1118\u001b[0m chunk_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m(arr[start_i:end_i] \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m data_list))\n\u001b[1;32m-> 1119\u001b[0m num_inserted \u001b[38;5;241m=\u001b[39m \u001b[43mexec_insert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;66;03m# GH 46891\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ambiente_desarrollo\\dev-empresas-negocios-env\\Lib\\site-packages\\pandas\\io\\sql.py:1010\u001b[0m, in \u001b[0;36mSQLTable._execute_insert\u001b[1;34m(self, conn, keys, data_iter)\u001b[0m\n\u001b[0;32m   1009\u001b[0m data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(keys, row)) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m data_iter]\n\u001b[1;32m-> 1010\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mrowcount\n",
      "File \u001b[1;32mc:\\ambiente_desarrollo\\dev-empresas-negocios-env\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1418\u001b[0m, in \u001b[0;36mConnection.execute\u001b[1;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1419\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNO_OPTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ambiente_desarrollo\\dev-empresas-negocios-env\\Lib\\site-packages\\sqlalchemy\\sql\\elements.py:515\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[1;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[1;32m--> 515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ambiente_desarrollo\\dev-empresas-negocios-env\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1640\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[1;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[0;32m   1632\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[0;32m   1633\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[0;32m   1634\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1638\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[0;32m   1639\u001b[0m )\n\u001b[1;32m-> 1640\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1651\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n",
      "File \u001b[1;32mc:\\ambiente_desarrollo\\dev-empresas-negocios-env\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1846\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1846\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ambiente_desarrollo\\dev-empresas-negocios-env\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1986\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1985\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1986\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1987\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1988\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1990\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\ambiente_desarrollo\\dev-empresas-negocios-env\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2353\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[0;32m   2352\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2353\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   2354\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ambiente_desarrollo\\dev-empresas-negocios-env\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1967\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1967\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1968\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1969\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[1;32mc:\\ambiente_desarrollo\\dev-empresas-negocios-env\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:924\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 924\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIntegrityError\u001b[0m: (psycopg2.errors.NotNullViolation) el valor nulo en la columna «id_ejecucion» de la relación «tb_resumen_cargue» viola la restricción de no nulo\nDETAIL:  La fila que falla contiene (null, 2025-02-07 10:33:50, null, null, db_dwh_corporativo.ventas.extract_rr_ventas_dig, 0, tb_datos_crudos_fibra_optica, 2).\n\n[SQL: INSERT INTO control_procesamiento.tb_resumen_cargue (id_ejecucion, fecha_inicio_procesamiento, fuentes, cantidad_registros, destino, id_estado) VALUES (%(id_ejecucion)s, %(fecha_inicio_procesamiento)s, %(fuentes)s, %(cantidad_registros)s, %(destino)s, %(id_estado)s)]\n[parameters: {'id_ejecucion': None, 'fecha_inicio_procesamiento': datetime.datetime(2025, 2, 7, 10, 33, 50), 'fuentes': 'db_dwh_corporativo.ventas.extract_rr_ventas_dig', 'cantidad_registros': 0, 'destino': 'tb_datos_crudos_fibra_optica', 'id_estado': 2}]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 45\u001b[0m\n\u001b[0;32m     43\u001b[0m funcion_error\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m descripcion_error\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(e)[:\u001b[38;5;241m100\u001b[39m])\n\u001b[1;32m---> 45\u001b[0m \u001b[43minsertarErroresDB\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[40], line 45\u001b[0m, in \u001b[0;36minsertarErroresDB\u001b[1;34m()\u001b[0m\n\u001b[0;32m     43\u001b[0m     nombre_tabla \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtb_errores_cargue\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     44\u001b[0m     errores\u001b[38;5;241m.\u001b[39mto_sql(nombre_tabla, con\u001b[38;5;241m=\u001b[39mconexion_errores, schema\u001b[38;5;241m=\u001b[39mnombre_esquema, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 45\u001b[0m     \u001b[43mcargueResumen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mid_ejecucion_en_curso\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfecha_inicio_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdb_dwh_corporativo.ventas.extract_rr_ventas_dig\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mpar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdestino_macrofo\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m     46\u001b[0m     salidaLogMonitoreo()\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SQLAlchemyError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[1;32mIn[39], line 41\u001b[0m, in \u001b[0;36mcargueResumen\u001b[1;34m(id_ejecucion, fecha_inicio_date, fuentes, cantidad_registros, destino, estado)\u001b[0m\n\u001b[0;32m     37\u001b[0m     df_resumen_cargue\u001b[38;5;241m.\u001b[39mto_sql(nombre_tabla, con\u001b[38;5;241m=\u001b[39mconexion, schema\u001b[38;5;241m=\u001b[39mnombre_esquema, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SQLAlchemyError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 41\u001b[0m     \u001b[43mfuentes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdb_dwh_corporativo.ventas.extract_rr_ventas_dig\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     42\u001b[0m     cantidad_registros\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     43\u001b[0m     estado\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Configuración del logging, generación del UUID de ejecución y consulta a la base de datos\n",
    "        configurarLogging()\n",
    "        id_ejecucion = generate_uuid().upper()\n",
    "        fecha_inicio = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        fecha_inicio_date = datetime.strptime(fecha_inicio, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        df_resultado_digitadas_rr = ejecutarConsultaOdbc()\n",
    "        if df_resultado_digitadas_rr is not None:\n",
    "            registros = len(df_resultado_digitadas_rr)\n",
    "            #print('bandera_0')\n",
    "            if registros > 0:\n",
    "                #print('bandera_1')\n",
    "                # Realiza la selección de campos y agrega información adicional\n",
    "                df_base = seleccionCamposdigitadasrr(df_resultado_digitadas_rr, fecha_inicio_date, id_ejecucion)\n",
    "                \n",
    "                \n",
    "                if df_base is not None:\n",
    "                    conteo_cargue = len(df_base)\n",
    "                    df_resumen = cargueResumen(id_ejecucion, fecha_inicio_date, 'db_dwh_corporativo.extract_rr_ventas_dig', conteo_cargue, 'tb_datos_crudos_denodo_digitadas_rr', 1)\n",
    "                    cargueDatosBD(df_base)\n",
    "                    cantidad_registros.append(conteo_cargue)\n",
    "                    fuentes.append('db_dwh_corporativo.extract_rr_ventas_dig')\n",
    "                \n",
    "        else:\n",
    "            print('sin cargue de resumen de datos en base de datos principal')            \n",
    "                \n",
    "        fecha_fin = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        fecha_fin_date = datetime.strptime(fecha_fin, \"%Y-%m-%d %H:%M:%S\")\n",
    "        duracion_proceso = fecha_fin_date - fecha_inicio_date\n",
    "        duracion_proceso_seg = int(duracion_proceso.total_seconds())\n",
    "        actualizarFechaFinProcesamiento(id_ejecucion, fecha_fin_date, duracion_proceso_seg)\n",
    "        duracion.append(str(duracion_proceso))\n",
    "        estado.append(1)\n",
    "        salidaLogMonitoreo()\n",
    "        \n",
    "    \n",
    "    except Exception as e:\n",
    "        fuentes.append('db_dwh_corporativo.extract_rr_ventas_dig')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(\"__main__\")\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        insertarErroresDB()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "dev-empresas-negocios-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
