{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl as opn\n",
    "import psycopg2\n",
    "from psycopg2 import sql, Error, OperationalError\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "import os\n",
    "import shutil  # Para mover el archivo descargado\n",
    "import logging\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "import sys\n",
    "import ast\n",
    "sys.path.append('C:\\\\ambiente_desarrollo\\\\dev-empresas-negocios-env\\\\desarrollo_notebook')\n",
    "import parametros_desarrollo as par\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Ruta al archivo Excel\n",
    "ruta_excel_causales = r\"C:\\Users\\46196682\\OneDrive - Comunicacion Celular S.A.- Comcel S.A\\BasesMantenimiento - bases\\Causales.xlsx\" ## dejar en parametros produccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VARIABLES GLOBALES\n",
    "fecha_actual = datetime.today().date()\n",
    "duracion = []\n",
    "fuentes = []\n",
    "cantidad_registros = []\n",
    "estado = []\n",
    "fecha_fin_procesamiento =[]\n",
    "funcion_error = []\n",
    "descripcion_error = []\n",
    "id_ejecucion = str(uuid.uuid4())  # Generar UUID de ejecución\n",
    "destino = 'Causales'\n",
    "id_estado = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def salidaLogMonitoreo():\n",
    "    \n",
    "    Este metodo captura la informacion que se desea imprimir en el Log\n",
    "    para monitoreo y funcionamiento del desarrollo\n",
    "    Argumentos:\n",
    "        None\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        None\n",
    "    \n",
    "    Fecha_fin = datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "    print(f\"Fecha_inicio: {fecha_inicio}\")\n",
    "    print(f\"Fecha_fin: {Fecha_fin}\")\n",
    "    print(f\"Duracion: {duracion}\")\n",
    "    print(f\"Fuentes: {fuentes}\")\n",
    "    print(f\"Cantidad_registros: {cantidad_registros}\")\n",
    "    print(f\"Destino: {destino}\")\n",
    "    print(f\"Estado: {estado}\")\n",
    "    print(\"Lugar errores: \", ' | '.join(map(str, funcion_error)))\n",
    "    print(\"Descripción errores: \", ' | '.join(map(str, descripcion_error)))\n",
    "    if estado[0] == 1 :\n",
    "        print(\"Ejecución exitosa\")\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "\n",
    "\"\"\"\n",
    "def salidaLogMonitoreo():\n",
    "    \"\"\"\n",
    "    Este método captura la información que se desea imprimir en el Log\n",
    "    para monitoreo y funcionamiento del desarrollo.\n",
    "    \"\"\"\n",
    "    Fecha_fin = datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "    logging.info(f\"Fecha_inicio: {fecha_inicio}\")\n",
    "    logging.info(f\"Fecha_fin: {Fecha_fin}\")\n",
    "    logging.info(f\"Duracion: {duracion}\")\n",
    "    logging.info(f\"Fuentes: {fuentes}\")\n",
    "    logging.info(f\"Cantidad_registros: {cantidad_registros}\")\n",
    "    logging.info(f\"Destino: {destino}\")\n",
    "    logging.info(f\"Estado: {estado}\")\n",
    "    logging.info(\"Lugar errores: \" + ' | '.join(map(str, funcion_error)))\n",
    "    logging.info(\"Descripción errores: \" + ' | '.join(map(str, descripcion_error)))\n",
    "    if estado[0] == 1:\n",
    "        logging.info(\"Ejecución exitosa\")\n",
    "    logging.info(\"------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para cargar resumen de datos en la BD\n",
    "def cargueResumen(id_ejecucion, fecha_inicio_date,fecha_fin_procesamiento, duracion,fuentes, cantidad_registros, destino, id_estado):\n",
    "    try:\n",
    "        df_resumen_cargue = pd.DataFrame({\n",
    "        'id_ejecucion': [id_ejecucion],  # Envolver en una lista\n",
    "        'fecha_inicio_procesamiento': [fecha_inicio_date],\n",
    "        'fecha_fin_procesamiento': [fecha_fin_procesamiento], \n",
    "        'duracion_segundos': [duracion],\n",
    "        'fuentes': [fuentes],\n",
    "        'cantidad_registros': [cantidad_registros],\n",
    "        'destino': [destino],\n",
    "        'id_estado': [id_estado],\n",
    "    })\n",
    "        Usuario_pro = 'postgres'\n",
    "        contraseña_pro = '1Nt3l163nC14_C0m3rc14L'\n",
    "        conexion = create_engine(f'postgresql://{par.usuario}:{par.contrasena}@{par.host}:{par.port}/{par.bd_inteligencia_comercial}')\n",
    "        # Especificar el esquema y la tabla en la que deseas insertar los datos\n",
    "        nombre_esquema = 'control_procesamiento'\n",
    "        nombre_tabla = 'tb_resumen_cargue'\n",
    "        \n",
    "        df_resumen_cargue.to_sql(nombre_tabla, con=conexion, schema=nombre_esquema, if_exists='append', index=False)\n",
    "    \n",
    "    except SQLAlchemyError as e:\n",
    "        fuentes.append('Causales')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(cargueResumen.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        salidaLogMonitoreo()\n",
    "    finally:\n",
    "        conexion.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configurarLogging():\n",
    "    \"\"\"\n",
    "    Configura el logging para escribir en un archivo y en la salida estándar\n",
    "    Utiliza la ruta definida en par.ruta_log para el directorio de logs.\n",
    "    \n",
    "    Argumentos:\n",
    "        None\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        None\n",
    "    \"\"\"\n",
    "    # Configuración del logging\n",
    "    log_directory = par.ruta_log  # Usa la ruta definida en config.py\n",
    "    log_file = os.path.join(log_directory, \"Causales.log\")\n",
    "\n",
    "    # Crear el directorio si no existe\n",
    "    if not os.path.exists(log_directory):\n",
    "        os.makedirs(log_directory)\n",
    "\n",
    "    # Configurar el logger\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file, mode='a'),  # 'a' para modo append\n",
    "            #logging.StreamHandler()  # Para imprimir en pantalla\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertarErroresDB():\n",
    "    \"\"\"\n",
    "    Metodo para insertar a POSTGRESQL los errores capturados durante la ejecución\n",
    "    Argumentos Globales:\n",
    "        fecha_inicio: Captura la fecha en que inicio la ejecución\n",
    "        fecha_fin: Captura la fecha en que finalizo la ejecución\n",
    "        duracion: Duración del procesamiento\n",
    "        fuente: Indica la fuente de donde provienen los datos\n",
    "        cantidad_registros: Cantidad de registros por fuente\n",
    "        destino: Indica la tabla a donde se estan ingestando los datos\n",
    "        id_estado: Indica el estado del proceso definidos en la base de datos \n",
    "        funcion_error: Indica la función donde se esta presentando una falla\n",
    "        descripcion_error: Descripción del error generado\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        SQLAlchemyError as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convertir las cadenas de texto a objetos datetime\n",
    "        fecha_inicio_tr = datetime.strptime(fecha_inicio, \"%Y-%m-%d %H:%M:%S\")\n",
    "        fecha_fin = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        fecha_fin_tr = datetime.strptime(fecha_fin, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        duracion_proceso_timedelta = fecha_fin_tr - fecha_inicio_tr\n",
    "        duracion_proceso_seconds = duracion_proceso_timedelta.total_seconds()\n",
    "        \n",
    "        errores = pd.DataFrame({\n",
    "            'fecha_inicio': fecha_inicio,\n",
    "            'fecha_fin': fecha_fin,\n",
    "            'duracion': duracion_proceso_seconds,\n",
    "            'fuente': fuentes,\n",
    "            'cantidad_registros': cantidad_registros,\n",
    "            'destino': destino,\n",
    "            'id_estado': estado,\n",
    "            'funcion_error': funcion_error,\n",
    "            'descripcion_error': descripcion_error\n",
    "        })\n",
    "        \n",
    "        conexion_errores = create_engine(f'postgresql://{par.usuario}:{par.contrasena}@{par.host}:{par.port}/{par.bd_inteligencia_comercial}')\n",
    "        # Especificar el esquema y la tabla en la que deseas insertar los datos\n",
    "        nombre_esquema = 'control_procesamiento'\n",
    "        nombre_tabla = 'tb_errores_cargue'\n",
    "        errores.to_sql(nombre_tabla, con=conexion_errores, schema=nombre_esquema, if_exists='append', index=False)\n",
    "        cargueResumen(id_ejecucion_en_curso, fecha_inicio_tr,2) \n",
    "        salidaLogMonitoreo()\n",
    "\n",
    "    \n",
    "    except SQLAlchemyError as e:\n",
    "        fuentes.append('Causales')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(insertarErroresDB.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        salidaLogMonitoreo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargueDatosBD(df_final):\n",
    "    \"\"\"\n",
    "    Función que se encarga de cargar los dataframes procesados hacia la base de datos\n",
    "    \n",
    "    Argumentos:\n",
    "        df_final: Contiene el dataframe que se requiere cargar a la BD\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        SQLAlchemyError as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "        conexion = create_engine(f'postgresql://{par.usuario}:{par.contrasena}@{par.host}:{par.port}/{par.bd_inteligencia_comercial}')\n",
    "        # Especificar el esquema y la tabla en la que deseas insertar los datos\n",
    "        nombre_esquema = 'fuentes_cruda'\n",
    "        nombre_tabla = 'tb_datos_crudos_causales'\n",
    "        \n",
    "        df_final.to_sql(nombre_tabla, con=conexion, schema=nombre_esquema, if_exists='append', index=False)\n",
    "        \n",
    "    except SQLAlchemyError as e:\n",
    "        fuentes.append('Causales')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(cargueDatosBD.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        insertarErroresDB()\n",
    "        salidaLogMonitoreo()\n",
    "    finally:\n",
    "        conexion.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consultarHistoricoCausales():\n",
    "    \"\"\"\n",
    "    Función que consulta los datos historicos existentes en la base de datos de la tabla de tb_datos_crudos_legalizadas\n",
    "    \n",
    "    Argumentos:\n",
    "        None\n",
    "    Retorna: \n",
    "        df_historico_mb : Retorna el historico de los datos cargados en la BD\n",
    "    Excepciones manejadas: \n",
    "        Exception as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "    try:\n",
    "        engine = create_engine(f'postgresql://{par.usuario}:{par.contrasena}@{par.host}:{par.port}/{par.bd_inteligencia_comercial}')\n",
    "\n",
    "        #engine = conexion_BD()\n",
    "        sql_consulta = \"Select * \\\n",
    "                    from fuentes_cruda.tb_datos_crudos_causales\"\n",
    "        df_historico_mb = pd.read_sql(sql_consulta, engine)\n",
    "    \n",
    "    \n",
    "        return df_historico_mb\n",
    "        \n",
    "    except Exception as e:\n",
    "        fuentes.append('Causales')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(consultarHistoricoCausales.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        insertarErroresDB()\n",
    "        salidaLogMonitoreo()\n",
    "    finally:\n",
    "        engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>razon_inicial</th>\n",
       "      <th>tipo</th>\n",
       "      <th>tipo_v</th>\n",
       "      <th>tipo_g</th>\n",
       "      <th>td</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Act por Reinstalación - 110</td>\n",
       "      <td>REINSTALACIONES</td>\n",
       "      <td>BAJAS</td>\n",
       "      <td>BAJAS</td>\n",
       "      <td>Reinstalaciones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Act Prepago a Postpago - 57</td>\n",
       "      <td>PREPOS</td>\n",
       "      <td>PREPOS</td>\n",
       "      <td>ALTAS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Act Retención Pre-Post - 118</td>\n",
       "      <td>REINSTALACIONES</td>\n",
       "      <td>BAJAS</td>\n",
       "      <td>BAJAS</td>\n",
       "      <td>Reinstalaciones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Act. de Pre a Post TMK. - 309</td>\n",
       "      <td>PREPOS</td>\n",
       "      <td>PREPOS</td>\n",
       "      <td>ALTAS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Act. Estrategia de Pre a Post TMK. - 308</td>\n",
       "      <td>PREPOS</td>\n",
       "      <td>PREPOS</td>\n",
       "      <td>ALTAS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              razon_inicial             tipo  tipo_v tipo_g  \\\n",
       "0               Act por Reinstalación - 110  REINSTALACIONES   BAJAS  BAJAS   \n",
       "1               Act Prepago a Postpago - 57           PREPOS  PREPOS  ALTAS   \n",
       "2              Act Retención Pre-Post - 118  REINSTALACIONES   BAJAS  BAJAS   \n",
       "3             Act. de Pre a Post TMK. - 309           PREPOS  PREPOS  ALTAS   \n",
       "4  Act. Estrategia de Pre a Post TMK. - 308           PREPOS  PREPOS  ALTAS   \n",
       "\n",
       "                td  \n",
       "0  Reinstalaciones  \n",
       "1              NaN  \n",
       "2  Reinstalaciones  \n",
       "3              NaN  \n",
       "4              NaN  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def df_Causales_f(ruta_excel_causales):\n",
    "    \"\"\"\n",
    "    Función para leer y procesar la hoja 'Causales' desde un archivo Excel.\n",
    "\n",
    "    Procesos:\n",
    "        - Lee la hoja 'Causales' del archivo especificado.\n",
    "        - Verifica si la columna 'RAZON_INICIAL' existe en los datos.\n",
    "        - Limpia los nombres de las columnas, eliminando espacios y convirtiendo a minúsculas.\n",
    "        - Elimina registros duplicados considerando las columnas clave.\n",
    "\n",
    "    Argumentos:\n",
    "        ruta_excel_causales (str): Ruta completa del archivo Excel que contiene la hoja 'Causales'.\n",
    "\n",
    "    Retorna:\n",
    "        pd.DataFrame: DataFrame con los datos únicos y columnas procesadas, o None si ocurre un error.\n",
    "\n",
    "    Excepciones manejadas:\n",
    "        Exception as e: Captura y registra cualquier error durante la lectura o procesamiento del archivo Excel.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Leer el archivo Excel y especificar la hoja\n",
    "        df_causales_a = pd.read_excel(ruta_excel_causales, sheet_name='Causales')\n",
    "        \n",
    "        # Verifica si la columna 'NIT' existe en el Excel\n",
    "        if 'RAZON_INICIAL' not in df_causales_a.columns:\n",
    "            print(\"La columna 'RAZON_INICIAL' no se encuentra en el archivo Excel.\")\n",
    "            return None\n",
    "        df_causales_a.columns = [col.replace(\" \", \"_\").lower() for col in df_causales_a.columns]  # Convertir nombres de columnas a minúsculas\n",
    "        df_causales_a = df_causales_a.drop_duplicates(subset=['razon_inicial', 'tipo', 'tipo_v', 'tipo_g', 'td'])\n",
    "        return df_causales_a\n",
    "    \n",
    "    except Exception as e:\n",
    "        fuentes.append('Causales')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(df_Causales_f.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        insertarErroresDB()\n",
    "        salidaLogMonitoreo()\n",
    "    \n",
    "#df_causales = df_Causales_f(ruta_excel)\n",
    "#df_causales.head(5)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Bloque principal de ejecución del proceso ETL para la tabla 'Causales'.\n",
    "\n",
    "    Funcionalidades:\n",
    "        - Configura el logging.\n",
    "        - Genera identificadores únicos para la ejecución.\n",
    "        - Calcula la duración del proceso.\n",
    "        - Consulta el histórico de registros existentes en la BD.\n",
    "        - Lee los nuevos registros desde el archivo Excel.\n",
    "        - Genera llaves únicas de comparación para evitar duplicados.\n",
    "        - Compara y filtra los registros nuevos no existentes en la BD.\n",
    "        - Agrega columnas de trazabilidad: id_ejecucion, id, fecha_procesamiento, id_estado_registro.\n",
    "        - Carga los nuevos registros a la base de datos si existen.\n",
    "        - Registra un resumen de la carga en la tabla correspondiente.\n",
    "        - Maneja errores durante todo el proceso, registrándolos en la tabla de errores.\n",
    "\n",
    "    Variables:\n",
    "        id_ejecucion (str): UUID que identifica la ejecución.\n",
    "        fecha_inicio (str): Fecha y hora de inicio del proceso.\n",
    "        fecha_fin (str): Fecha y hora de fin del proceso.\n",
    "        estado (int): Indicador de estado del proceso (1 = éxito, 2 = error).\n",
    "        registros (int): Cantidad de registros nuevos a insertar.\n",
    "\n",
    "    Excepciones manejadas:\n",
    "        Exception as e: Captura cualquier error en el proceso y lo registra en la bitácora de errores.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        configurarLogging()\n",
    "        #Variables constantes dentro del codigo para funciones\n",
    "        \n",
    "\n",
    "        id_ejecucion = str(uuid.uuid4()).upper()  # Generar ID de ejecución\n",
    "        fecha_inicio = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        fecha_inicio_tr = datetime.strptime(fecha_inicio, \"%Y-%m-%d %H:%M:%S\")\n",
    "        fecha_fin = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        fecha_fin_tr = datetime.strptime(fecha_fin, \"%Y-%m-%d %H:%M:%S\")\n",
    "        id_estado = 1\n",
    "        estado = 1  # O el valor adecuado para el estado\n",
    "        duracion_proceso_timedelta = fecha_fin_tr - fecha_inicio_tr\n",
    "        duracion_proceso_seconds = duracion_proceso_timedelta.total_seconds()\n",
    "        \n",
    "\n",
    "        \n",
    "        df_CausalesHis = consultarHistoricoCausales()\n",
    "        df_CausalesHis['llaveDuplihis'] = df_CausalesHis['razon_inicial'].astype(str) + \\\n",
    "            df_CausalesHis['tipo'].astype(str) + \\\n",
    "            df_CausalesHis['tipo_v'].astype(str) + \\\n",
    "            df_CausalesHis['tipo_g'].astype(str) + \\\n",
    "            df_CausalesHis['td'].astype(str)\n",
    "\n",
    "\n",
    "        df_causales = df_Causales_f(ruta_excel_causales)\n",
    "        df_causales['id_ejecucion'] = id_ejecucion  # Agregar la columna id_ejecucion con el mismo UUID en todas las fila\n",
    "        df_causales['id'] = [str(uuid.uuid4()) for _ in range(len(df_causales))]  # Agregar la columna id con un UUID único por cada fila\n",
    "        df_causales['fecha_procesamiento'] = fecha_inicio  # Agregar la columna fecha_procesamiento con la fecha y hora actual\n",
    "        #df_causales['id_estado'] = 1  \n",
    "        df_causales['id_estado_registro'] = 1\n",
    "        \n",
    "        df_causales['llaveDuplihis'] = df_causales['razon_inicial'].astype(str) + \\\n",
    "            df_causales['tipo'].astype(str) + \\\n",
    "            df_causales['tipo_v'].astype(str) + \\\n",
    "            df_causales['tipo_g'].astype(str) + \\\n",
    "            df_causales['td'].astype(str)\n",
    " \n",
    "\n",
    "        df_Causalesfin_a = pd.merge(df_causales, df_CausalesHis[['llaveDuplihis']], \n",
    "                    on=['llaveDuplihis'], \n",
    "                    how='left', \n",
    "                    indicator=True)\n",
    "        \n",
    "        df_Causalesfin = df_Causalesfin_a[df_Causalesfin_a['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "        \n",
    "        df_Causalesfin.drop(columns=['llaveDuplihis'], inplace=True)\n",
    "\n",
    "        registros = len(df_Causalesfin)\n",
    "        cantidad_registros.append(registros)\n",
    "\n",
    "        # Ejecucion cargue de datos ETL, se carga la funcion de CargueDatosBD, insercion a BD\n",
    "        if registros > 0:\n",
    "           df_resumen = cargueResumen(\n",
    "        id_ejecucion, fecha_inicio_tr, fecha_fin_tr, duracion_proceso_seconds,\n",
    "        'Causales', registros, 'tb_datos_crudos_causales', id_estado\n",
    "        )\n",
    "        cargueDatosBD(df_Causalesfin)\n",
    "  \n",
    "    except Exception as e:\n",
    "        fuentes.append('Causales')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(\"__main__\")\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        insertarErroresDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntb_datos_crudos_Causales\\n    \\n    razon_inicial VARCHAR(255),\\n    tipo VARCHAR(255), \\n    tipo_v VARCHAR(255), \\n    tipo_g VARCHAR(255),\\n    td VARCHAR(255),\\n    id_ejecucion VARCHAR(255),\\n    id VARCHAR(255) PRIMARY KEY,\\n    fecha_procesamiento VARCHAR(255),\\n    id_estado INT,\\n    id_estado_registro INT\\n'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "tb_datos_crudos_Causales\n",
    "    \n",
    "    razon_inicial VARCHAR(255),\n",
    "    tipo VARCHAR(255), \n",
    "    tipo_v VARCHAR(255), \n",
    "    tipo_g VARCHAR(255),\n",
    "    td VARCHAR(255),\n",
    "    id_ejecucion VARCHAR(255),\n",
    "    id VARCHAR(255) PRIMARY KEY,\n",
    "    fecha_procesamiento VARCHAR(255),\n",
    "    id_estado INT,\n",
    "    id_estado_registro INT\n",
    "\"\"\"    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
