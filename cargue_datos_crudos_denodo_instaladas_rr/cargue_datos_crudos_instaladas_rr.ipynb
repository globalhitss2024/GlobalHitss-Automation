{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20fa1dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n***************************************************************************************\\n* CLARO  HITSS - EMPRESAS Y NEGOCIOS                                                  *\\n* OBJETIVO: Extración de fuentes crudas de instalada RR                               * \\n*           y cargue a base de datos de forma automatica                              *\\n*           Comunicacion Celular S.A.- Comcel S.A\\\\Wilmer Camargo Ochoa - Data_PCC     *\\n* TABLA DE INGESTA POSTGRESQL: tb_datos_crudos_denodo_instaladas_rr                   *\\n* FECHA CREACION: 05 de Septiembre de 2024                                            *\\n* ELABORADO POR: LAURA GAITAN                                                         *\\n* *************************************************************************************\\n* MODIFICACIONES\\n* NOMBRE                   FECHA      VERSION            DESCRIPCION\\n* \\n*\\n***************************************************************************************\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "***************************************************************************************\n",
    "* CLARO  HITSS - EMPRESAS Y NEGOCIOS                                                  *\n",
    "* OBJETIVO: Extración de fuentes crudas de instalada RR                               * \n",
    "*           y cargue a base de datos de forma automatica                              *\n",
    "*           Comunicacion Celular S.A.- Comcel S.A\\Wilmer Camargo Ochoa - Data_PCC     *\n",
    "* TABLA DE INGESTA POSTGRESQL: tb_datos_crudos_denodo_instaladas_rr                   *\n",
    "* FECHA CREACION: 05 de Septiembre de 2024                                            *\n",
    "* ELABORADO POR: LAURA GAITAN                                                         *\n",
    "* *************************************************************************************\n",
    "* MODIFICACIONES\n",
    "* NOMBRE                   FECHA      VERSION            DESCRIPCION\n",
    "* \n",
    "*\n",
    "***************************************************************************************\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e1597ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib3\n",
    "urllib3.disable_warnings()\n",
    "from datetime import datetime\n",
    "import pyodbc\n",
    "import sys\n",
    "sys.path.append('C:/ambiente_desarrollo/dev-empresas-negocios-env/desarrollo_notebook')\n",
    "import parametros_desarrollo as par\n",
    "import uuid\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "import os\n",
    "import psycopg2\n",
    "import logging\n",
    "import pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37db7930",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#VARIABLES GLOBALES\n",
    "fecha_inicio = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "fecha_actual = datetime.today().date()\n",
    "duracion = []\n",
    "fuentes = []\n",
    "cantidad_registros = []\n",
    "destino = ['tb_datos_crudos_denodo_instaladas_rr']\n",
    "estado = []\n",
    "funcion_error = []\n",
    "descripcion_error = []\n",
    "id_ejecucion_en_curso = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb214086",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def salidaLogMonitoreo():\n",
    "    \n",
    "    Este metodo captura la informacion que se desea imprimir en el Log\n",
    "    para monitoreo y funcionamiento del desarrollo\n",
    "    Argumentos:\n",
    "        None\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        None\n",
    "    \n",
    "    Fecha_fin = datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "    print(f\"Fecha_inicio: {fecha_inicio}\")\n",
    "    print(f\"Fecha_fin: {Fecha_fin}\")\n",
    "    print(f\"Duracion: {duracion}\")\n",
    "    print(f\"Fuentes: {fuentes}\")\n",
    "    print(f\"Cantidad_registros: {cantidad_registros}\")\n",
    "    print(f\"Destino: {destino}\")\n",
    "    print(f\"Estado: {estado}\")\n",
    "    print(\"Lugar errores: \", ' | '.join(map(str, funcion_error)))\n",
    "    print(\"Descripción errores: \", ' | '.join(map(str, descripcion_error)))\n",
    "    if estado[0] == 1 :\n",
    "        print(\"Ejecución exitosa\")\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "\n",
    "\"\"\"\n",
    "def salidaLogMonitoreo():\n",
    "    \"\"\"\n",
    "    Este método captura la información que se desea imprimir en el Log\n",
    "    para monitoreo y funcionamiento del desarrollo.\n",
    "    \"\"\"\n",
    "    Fecha_fin = datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "    logging.info(f\"Fecha_inicio: {fecha_inicio}\")\n",
    "    logging.info(f\"Fecha_fin: {Fecha_fin}\")\n",
    "    logging.info(f\"Duracion: {duracion}\")\n",
    "    logging.info(f\"Fuentes: {fuentes}\")\n",
    "    logging.info(f\"Cantidad_registros: {cantidad_registros}\")\n",
    "    logging.info(f\"Destino: {destino}\")\n",
    "    logging.info(f\"Estado: {estado}\")\n",
    "    logging.info(\"Lugar errores: \" + ' | '.join(map(str, funcion_error)))\n",
    "    logging.info(\"Descripción errores: \" + ' | '.join(map(str, descripcion_error)))\n",
    "    if estado[0] == 1:\n",
    "        logging.info(\"Ejecución exitosa\")\n",
    "    logging.info(\"------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed076c09",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def cargueResumen(id_ejecucion, fecha_inicio_date,fuentes,cantidad_registros,destino,estado):\n",
    "    \"\"\"\n",
    "    Función que se encarga de cargar estadisticas de los datos que estan siendo procesados\n",
    "    \n",
    "    Argumentos:\n",
    "        id_ejecucion: Contiene un numero alfanumerico para creación de llaves primarias y foraneas de la base de datos\n",
    "        fecha_inicio_date: Fecha de inicio del procesamiento\n",
    "        fecha_fin_date: Fecha de fin del procesamiento\n",
    "        duracion_proceso: Duración del procesamiento \n",
    "        fuentes: Fuentes de donde provienen los datos\n",
    "        cantidad_registros: Cantidad de registros procesados\n",
    "        destino: Tabla donde se ingestan los datos\n",
    "        estado: Indica el estado del proceso de acuerdo a lo definido en la base de datos en la tabla control_procesamiento.estados_cargue \n",
    "        \n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        SQLAlchemyError as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        \n",
    "        df_resumen_cargue = pd.DataFrame({\n",
    "            'id_ejecucion': id_ejecucion,\n",
    "            'fecha_inicio_procesamiento': fecha_inicio_date,\n",
    "            'fuentes': fuentes,\n",
    "            'cantidad_registros': cantidad_registros,\n",
    "            'destino': [destino],\n",
    "            'id_estado': [estado],\n",
    "        })\n",
    "\n",
    "        conexion = create_engine(f'postgresql://{par.usuario}:{par.contrasena}@{par.host}:{par.port}/{par.bd_inteligencia_comercial}')\n",
    "        # Especificar el esquema y la tabla en la que deseas insertar los datos\n",
    "        nombre_esquema = 'control_procesamiento'\n",
    "        nombre_tabla = 'tb_resumen_cargue'\n",
    "        \n",
    "        df_resumen_cargue.to_sql(nombre_tabla, con=conexion, schema=nombre_esquema, if_exists='append', index=False)\n",
    "\n",
    "\n",
    "    except SQLAlchemyError as e:\n",
    "        fuentes.append('db_dwh_corporativo.extract_rr_ventas_ins')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(cargueResumen.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        salidaLogMonitoreo()\n",
    "    finally:\n",
    "        conexion.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ce11313",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def insertarErroresDB():\n",
    "    \"\"\"\n",
    "    Metodo para insertar a POSTGRESQL los errores capturados durante la ejecución\n",
    "    Argumentos Globales:\n",
    "        fecha_inicio: Captura la fecha en que inicio la ejecución\n",
    "        fecha_fin: Captura la fecha en que finalizo la ejecución\n",
    "        duracion: Duración del procesamiento\n",
    "        fuente: Indica la fuente de donde provienen los datos\n",
    "        cantidad_registros: Cantidad de registros por fuente\n",
    "        destino: Indica la tabla a donde se estan ingestando los datos\n",
    "        id_estado: Indica el estado del proceso definidos en la base de datos \n",
    "        funcion_error: Indica la función donde se esta presentando una falla\n",
    "        descripcion_error: Descripción del error generado\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        SQLAlchemyError as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convertir las cadenas de texto a objetos datetime\n",
    "        fecha_inicio_tr = datetime.strptime(fecha_inicio, \"%Y-%m-%d %H:%M:%S\")\n",
    "        fecha_fin = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        fecha_fin_tr = datetime.strptime(fecha_fin, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        duracion_proceso_timedelta = fecha_fin_tr - fecha_inicio_tr\n",
    "        duracion_proceso_seconds = duracion_proceso_timedelta.total_seconds()\n",
    "        \n",
    "        errores = pd.DataFrame({\n",
    "            'fecha_inicio': fecha_inicio,\n",
    "            'fecha_fin': fecha_fin,\n",
    "            'duracion': duracion_proceso_seconds,\n",
    "            'fuente': fuentes,\n",
    "            'cantidad_registros': cantidad_registros,\n",
    "            'destino': destino,\n",
    "            'id_estado': estado,\n",
    "            'funcion_error': funcion_error,\n",
    "            'descripcion_error': descripcion_error\n",
    "        })\n",
    "        \n",
    "        conexion_errores = create_engine(f'postgresql://{par.usuario}:{par.contrasena}@{par.host}:{par.port}/{par.bd_inteligencia_comercial}')\n",
    "        # Especificar el esquema y la tabla en la que deseas insertar los datos\n",
    "        nombre_esquema = 'control_procesamiento'\n",
    "        nombre_tabla = 'tb_errores_cargue'\n",
    "        errores.to_sql(nombre_tabla, con=conexion_errores, schema=nombre_esquema, if_exists='append', index=False)\n",
    "        cargueResumen(id_ejecucion_en_curso, fecha_inicio_tr,'db_dwh_corporativo.ventas..extract_rr_ventas_ins',0,par.destino_macrofo,2) \n",
    "        salidaLogMonitoreo()\n",
    "\n",
    "    \n",
    "    except SQLAlchemyError as e:\n",
    "        fuentes.append('db_dwh_corporativo.extract_rr_ventas_ins')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(insertarErroresDB.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        salidaLogMonitoreo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7c8b7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conexion_BD():\n",
    "    \"\"\"\n",
    "    Función que genera la conexión hacia la base de datos por medio de la libreria psycopg2\n",
    "    \n",
    "    Argumentos:\n",
    "        id_ejecucion: id del proceso ejecutado\n",
    "        fecha_fin_date: Fecha fin de procesamiento\n",
    "        duracion_proceso_seg: Duración en segundos del procesamiento\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        Exception as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "        conn = psycopg2.connect(\n",
    "            host=par.host,\n",
    "            database=par.bd_inteligencia_comercial,\n",
    "            user=par.usuario,\n",
    "            password=par.contrasena\n",
    "        )\n",
    "        return conn\n",
    "\n",
    "    except SQLAlchemyError as e:\n",
    "        fuentes.append('db_dwh_corporativo.extract_rr_ventas_ins')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(conexion_BD.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        salidaLogMonitoreo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad433359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conexionDenodoOdbc():\n",
    "    \"\"\"\n",
    "    Función que genera la conexión hacia la base de datos por medio de la libreria psycopg2\n",
    "    \n",
    "    Argumentos:\n",
    "        id_ejecucion: id del proceso ejecutado\n",
    "        fecha_fin_date: Fecha fin de procesamiento\n",
    "        duracion_proceso_seg: Duración en segundos del procesamiento\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        Exception as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "    try:\n",
    "        usuario_denodo=par.usuario_denodo\n",
    "        contraseña_denodo=par.contraseña_denodo\n",
    "        cadena=f'DSN=DenodoODBC;UID={usuario_denodo};PWD={contraseña_denodo}'\n",
    "        conn = pyodbc.connect(cadena)\n",
    "        return conn\n",
    "\n",
    "    except SQLAlchemyError as e:\n",
    "        fuentes.append('db_dwh_corporativo.extract_rr_ventas_ins')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(conexion_BD.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        salidaLogMonitoreo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b313c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConsultarIformacionAlmacenada(tabla_consulta):\n",
    "    \"\"\"\n",
    "    Función que consulta los datos historicos existentes en la base de datos de la tabla\n",
    "    \n",
    "    Argumentos:\n",
    "        None\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        Exception as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "    try:\n",
    "    \n",
    "        \n",
    "        engine = conexion_BD()\n",
    "        sql_consulta = f\"SELECT * FROM fuentes_cruda.{tabla_consulta}\"\n",
    "\n",
    "        df_tabla_bd = pd.read_sql(sql_consulta, engine)\n",
    "\n",
    "        return df_tabla_bd\n",
    "     \n",
    "       \n",
    "    except Exception as e:\n",
    "        fuentes.append('db_dwh_corporativo.extract_rr_ventas_ins')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(ConsultarIformacionAlmacenada.__name__)\n",
    "        descripcion_error.append(str(e))\n",
    "        insertarErroresDB()\n",
    "        salidaLogMonitoreo()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49c70e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ejecutarConsultaOdbc():\n",
    "    \"\"\"\n",
    "    Método para ejecutar una consulta y devolver los resultados en un DataFrame.\n",
    "    \"\"\"\n",
    "    conn = conexionDenodoOdbc()\n",
    "    \n",
    "    try:\n",
    "        #cur = conn.cursor()\n",
    "        query = \"SELECT * FROM db_dwh_corporativo.extract_rr_ventas_ins WHERE aumento != 0\"\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(query)\n",
    "        rows = cursor.fetchall()\n",
    "        df = pd.DataFrame.from_records(rows, columns=[desc[0] for desc in cursor.description])\n",
    "        print (f'cantidad de registros descargados para instaladas rr: {df.shape[0]}')\n",
    "        df_resultado = df\n",
    "        #df_resultado = ordenColumnas(df,1)\n",
    "        return df_resultado\n",
    "    \n",
    "    except pyodbc.Error as e:\n",
    "        if 1 in estado:\n",
    "            estado.remove(1)\n",
    "        if 2 not in estado:\n",
    "            estado.append(2)\n",
    "        cantidad_registros.append(0)\n",
    "        funcion_error.append(ejecutarConsultaOdbc.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        insertarErroresDB()\n",
    "        salidaLogMonitoreo()\n",
    "        return None\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "167a5c24",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def actualizarFechaFinProcesamiento(id_ejecucion, fecha_fin_date, duracion_proceso_seg):\n",
    "\n",
    "    \"\"\"\n",
    "    Función que actualiza la fecha fin de procesamiento y duración para el proceso que se ejecuto.\n",
    "    Utilizando cursores\n",
    "    \n",
    "    Argumentos:\n",
    "        id_ejecucion: id del proceso ejecutado\n",
    "        fecha_fin_date: Fecha fin de procesamiento\n",
    "        duracion_proceso_seg: Duración en segundos del procesamiento\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        Exception as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "        conn = conexion_BD()\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        update_query = \"\"\"\n",
    "            UPDATE control_procesamiento.tb_resumen_cargue \n",
    "            SET fecha_fin_procesamiento = %s,\n",
    "            duracion_segundos = %s\n",
    "            WHERE id_ejecucion = %s\n",
    "        \"\"\"\n",
    "        cur.execute(update_query, (fecha_fin_date, duracion_proceso_seg, id_ejecucion))\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        fuentes.append('db_dwh_corporativo.extract_rr_ventas_ins')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(actualizarFechaFinProcesamiento.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        insertarErroresDB()\n",
    "        salidaLogMonitoreo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67193634",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def generate_uuid():\n",
    "    \"\"\"\n",
    "    Función que genera un numero alfanumerico para creación de llaves primarias y foraneas\n",
    "    \n",
    "    Argumentos:\n",
    "        None\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        Exception as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        return str(uuid.uuid4())\n",
    "    \n",
    "    except Exception as e:\n",
    "        fuentes.append('db_dwh_corporativo.extract_rr_ventas_ins')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(generate_uuid.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        insertarErroresDB()\n",
    "        salidaLogMonitoreo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "203288bf",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def configurarLogging():\n",
    "    \"\"\"\n",
    "    Configura el logging para escribir en un archivo y en la salida estándar\n",
    "    Utiliza la ruta definida en par.ruta_log para el directorio de logs.\n",
    "    \n",
    "    Argumentos:\n",
    "        None\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        None\n",
    "    \"\"\"\n",
    "    # Configuración del logging\n",
    "    log_directory = par.ruta_log  # Usa la ruta definida en config.py\n",
    "    log_file = os.path.join(log_directory, \"tb_datos_crudos_denodo_instaladas_rr.log\")\n",
    "\n",
    "    # Crear el directorio si no existe\n",
    "    if not os.path.exists(log_directory):\n",
    "        os.makedirs(log_directory)\n",
    "\n",
    "    # Configurar el logger\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file, mode='a'),  # 'a' para modo append\n",
    "            #logging.StreamHandler()  # Para imprimir en pantalla\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "265a6bf7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def cargueDatosBD(df_final):\n",
    "    \"\"\"\n",
    "    Función que se encarga de cargar los dataframes procesados hacia la base de datos\n",
    "    \n",
    "    Argumentos:\n",
    "        df_final: Contiene el dataframe que se requiere cargar a la BD\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        SQLAlchemyError as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "        conexion = create_engine(f'postgresql://{par.usuario}:{par.contrasena}@{par.host}:{par.port}/{par.bd_inteligencia_comercial}')\n",
    "        # Especificar el esquema y la tabla en la que deseas insertar los datos\n",
    "        nombre_esquema = 'fuentes_cruda'\n",
    "        nombre_tabla = 'tb_datos_crudos_denodo_instaladas_rr'\n",
    "        df_final.to_sql(nombre_tabla, con=conexion, schema=nombre_esquema, if_exists='append', index=False)\n",
    "       \n",
    "        \n",
    "    except SQLAlchemyError as e:\n",
    "        fuentes.append('db_dwh_corporativo.extract_rr_ventas_ins')\n",
    "        cantidad_registros.append(0)\n",
    "        if 1 in estado:\n",
    "            estado.remove(1)\n",
    "        if 2 not in estado:\n",
    "            estado.append(2)\n",
    "        funcion_error.append(cargueDatosBD.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        insertarErroresDB()\n",
    "        salidaLogMonitoreo()\n",
    "    finally:\n",
    "        conexion.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10bc68f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seleccionCamposinstaladasrr(df,fecha_inicio_date, id_ejecucion):\n",
    "    \"\"\"\n",
    "    Función encargada de seleccionar los datos relevantes de la base de datos de instaladas RR, \n",
    "    extraídos desde Denodo, y generar campos adicionales necesarios para el control \n",
    "    y procesamiento de los datos.\n",
    "\n",
    "    Argumentos:\n",
    "        df: DataFrame que contiene los datos de instaladas RR a procesar, extraídos de Denodo.\n",
    "        fecha_inicio_date: Fecha y hora en que comienza el procesamiento de los datos.\n",
    "        id_ejecucion: Identificador único de la ejecución, utilizado para la creación de claves primarias y foráneas en la base de datos.\n",
    "    \n",
    "    Retorna: \n",
    "        df_selected: DataFrame final con los datos seleccionados y enriquecidos, listo para ser insertado en la tabla de destino.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        df_base = df.copy()\n",
    "\n",
    "        df_base.rename(columns={\n",
    "            'cvacct':'id_cuenta',\n",
    "            'cvaon':'ot_orden_trabajo',\n",
    "            'cvanct':'numero_contrato',\n",
    "            'cvanom':'nombres',\n",
    "            'cvatid':'tipo_documento',\n",
    "            'cvanid':'numero_documento',\n",
    "            'cvapho':'numero_telefono_1',\n",
    "            'cvabph':'numero_telefono_2',\n",
    "            'cvatyp':'tipo_suscriptor_1',\n",
    "            'cvastr':'numero_calle',\n",
    "            'cvahom':'direccion_residencia',\n",
    "            'cvaapt':'numero_apartamento',\n",
    "            'cvaccd':'ciudad_venta',\n",
    "            'cvacde':'codigo_division',\n",
    "            'cvaust':'tipo_suscriptor_2',\n",
    "            'cvasta':'estado',\n",
    "            'cvatpe':'codigo_tarifa',\n",
    "            'cvatys':'nombre_servicio_1',\n",
    "            'cvarsc':'descripcion_servicio_1',\n",
    "            'cvaunt':'cvaunt',\n",
    "            'cvaser':'codigo_servicio',\n",
    "            'srvnam':'nombre_servicio_2',\n",
    "            'srvdes':'descripcion_servicio_2',\n",
    "            'cvasrv':'numero_servicios_1',\n",
    "            'cvapts':'cvapts',\n",
    "            'cvadlr':'numero_dealer',\n",
    "            'cvaase':'nombre_dealer',\n",
    "            'cvacoo':'coordinador',\n",
    "            'cvagas':'grupo_dealer',\n",
    "            'cvasty':'cvasty',\n",
    "            'cvatsu':'cvatsu',\n",
    "            'cvacod':'cvacod',\n",
    "            'cvaarg':'cvaarg',\n",
    "            'cvatse':'cvatse',\n",
    "            'cvaknd':'cvaknd',\n",
    "            'cvavaa':'cvavaa',\n",
    "            'cvarse':'cvarse',\n",
    "            'cvanod':'nodo',\n",
    "            'nodnbr':'nombre_nodo',\n",
    "            'cvafdi':'fecha_digitacion',\n",
    "            'cvazon':'cvazon',\n",
    "            'cvausu':'cvausu',\n",
    "            'cvafdc':'fecha_creacion_inicio_anio_1',\n",
    "            'cvafdy':'fecha_creacion_fin_anio_1',\n",
    "            'cvafdm':'fecha_creacion_mes_1',\n",
    "            'cvafdd':'fecha_creacion_dia_1',\n",
    "            'cvafcc':'fecha_creacion_inicio_anio_2',\n",
    "            'cvafcy':'fecha_creacion_fin_anio_2',\n",
    "            'cvafcm':'fecha_creacion_mes_2',\n",
    "            'cvafcd':'fecha_creacion_dia_2',\n",
    "            'cvafco':'fecha_creacion',\n",
    "            'cvatvt':'tipo_venta',\n",
    "            'cvataf':'cvataf',\n",
    "            'cvapr2':'cvapr2',\n",
    "            'cvadif':'val_dif_service',\n",
    "            'cvarme':'valor_servicio',\n",
    "            'cvarmp':'renta_wo_anterior',\n",
    "            'cvarmc':'renta_wo_actual',\n",
    "            'cvarmd':'diferencia_renta',\n",
    "            'cvalin':'numero_lineas_suscriptor',\n",
    "            'cvanus':'numero_servicios_2',\n",
    "            'cvaorg':'origen_datos',\n",
    "            'cvaca1':'campaña_1',\n",
    "            'cvaca2':'campaña_2',\n",
    "            'cvaca3':'campaña_3',\n",
    "            'cvamig':'cvamig',\n",
    "            'cvaeto':'estrato',\n",
    "            'cvinf2':'numeral_2',\n",
    "            'cvanoc':'conyugue',\n",
    "            'cvprbf':'cod_black_list',\n",
    "            'cvprbn':'desc_black_list',\n",
    "            'cvemfa':'correo1',\n",
    "            'cvinf1':'correo2',\n",
    "            'cvfchp':'fecha_permanencia',\n",
    "            'cvtred':'cvtred',\n",
    "            'cvstse':'id_servicio',\n",
    "            'cvdsts':'descripcion_servicio_3',\n",
    "            'cvrmac':'cvrmac',\n",
    "            'cvrman':'cvrman',\n",
    "            'cvndas':'numero_documento_2',\n",
    "            'cvnase':'detalle_servicio',\n",
    "            'cvpcam':'cvpcam',\n",
    "            'cvtpro':'cvtpro',\n",
    "            'cvtnes':'nobre_especialista',\n",
    "            'cvtarg':'area_gcia_vtas',\n",
    "            'cvtzng':'zona_gcia_vtas',\n",
    "            'cvtcan':'canal',\n",
    "            'cvtgvd':'aliado',\n",
    "            'cvtpob':'cvtpob',\n",
    "            'cvtarv':'area_venta',\n",
    "            'cvtznv':'zona_venta',\n",
    "            'tipo_linea':'tipo_red',\n",
    "            'fecha_sys':'fecha_sys',\n",
    "            'aumento':'aumento'\n",
    "        }, inplace=True)\n",
    "\n",
    "        df_historico = ConsultarIformacionAlmacenada('tb_datos_crudos_denodo_instaladas_rr')\n",
    "\n",
    "        \n",
    "        df_base['llave_compuesta'] = (\n",
    "        df_base['id_cuenta'].astype(str) + '-' +\n",
    "        df_base['ot_orden_trabajo'].fillna('').astype(str) + '-' +\n",
    "        df_base['codigo_servicio'].fillna('').astype(str))\n",
    "        \n",
    "        df_historico['id_cuenta'] = df_historico ['id_cuenta'].apply(lambda x: int(x))\n",
    "        df_historico['ot_orden_trabajo'] = df_historico ['ot_orden_trabajo'].apply(lambda x: int(x))\n",
    "        \n",
    "        df_historico['llave_compuesta'] = (\n",
    "        df_historico['id_cuenta'].astype(str) + '-' +\n",
    "        df_historico['ot_orden_trabajo'].fillna('').astype(str) + '-' +\n",
    "        df_historico['codigo_servicio'].fillna('').astype(str))\n",
    "        \n",
    "    \n",
    "        df_merged = pd.merge(df_base, df_historico[['llave_compuesta']], on='llave_compuesta', how='outer', indicator=True)\n",
    "        df_nuevos = df_merged[df_merged['_merge'] == 'left_only'].copy()\n",
    "        df_nuevos.drop(columns=['_merge'], inplace=True)\n",
    "        df_nuevos.drop(columns=['llave_compuesta'], inplace=True)\n",
    "      \n",
    "        df_nuevos = pd.concat([df_nuevos], ignore_index=True)\n",
    "\n",
    "        df_nuevos['id'] = [generate_uuid().upper() for _ in range(len(df_nuevos))]\n",
    "        df_nuevos['id_ejecucion'] = id_ejecucion\n",
    "        df_nuevos['fecha_procesamiento'] = pd.to_datetime(fecha_inicio_date)\n",
    "        df_nuevos['fuente'] = 'extract_rr_ventas_ins'\n",
    "        df_nuevos['id_estado'] = 1\n",
    "\n",
    "        df_nuevos['correo2'] = df_nuevos['correo2'].str.replace(r'(\\S+@\\S+\\.\\S+)\\.*', r'\\1', regex=True)\n",
    "        df_nuevos['descripcion_servicio_3'] = df_nuevos['descripcion_servicio_3'].str.replace(r'\\.+', '', regex=True)\n",
    "        df_nuevos['origen_datos'] = df_nuevos['origen_datos'].str.upper()\n",
    " \n",
    "        # Selección de columnas necesarias según la estructura de la tabla final\n",
    "        \n",
    "        df_nuevos = df_nuevos[[\n",
    "            'id', 'id_ejecucion','id_cuenta','ot_orden_trabajo','numero_contrato', 'nombres','tipo_documento','numero_documento',\n",
    "            'numero_telefono_1','numero_telefono_2','tipo_suscriptor_1','numero_calle','direccion_residencia','numero_apartamento',\n",
    "            'ciudad_venta', 'codigo_division','tipo_suscriptor_2','estado','codigo_tarifa','nombre_servicio_1','descripcion_servicio_1',\n",
    "            'cvaunt','codigo_servicio','nombre_servicio_2','descripcion_servicio_2','numero_servicios_1','cvapts','numero_dealer',\n",
    "            'nombre_dealer','coordinador','grupo_dealer','cvasty','cvatsu','cvacod','cvaarg','cvatse','cvaknd','cvavaa','cvarse',\n",
    "            'nodo','nombre_nodo','fecha_digitacion','cvazon','cvausu','fecha_creacion_inicio_anio_1','fecha_creacion_fin_anio_1','fecha_creacion_mes_1',\n",
    "            'fecha_creacion_dia_1','fecha_creacion_inicio_anio_2','fecha_creacion_fin_anio_2','fecha_creacion_mes_2','fecha_creacion_dia_2',\n",
    "            'fecha_creacion','tipo_venta','cvataf','cvapr2','val_dif_service','valor_servicio','renta_wo_anterior','renta_wo_actual',\n",
    "            'diferencia_renta','numero_lineas_suscriptor','numero_servicios_2','origen_datos','campaña_1','campaña_2','campaña_3','cvamig','estrato',\n",
    "            'numeral_2','conyugue','cod_black_list','desc_black_list','correo1','correo2','fecha_permanencia','cvtred','id_servicio','descripcion_servicio_3','cvrmac','cvrman',\n",
    "            'numero_documento_2','detalle_servicio','cvpcam','cvtpro', 'nobre_especialista','area_gcia_vtas','zona_gcia_vtas', 'canal','aliado','cvtpob','area_venta','zona_venta',\n",
    "            'tipo_red','fecha_sys','aumento','fecha_procesamiento', 'fuente', 'id_estado'\n",
    "        ]]\n",
    "    \n",
    "    \n",
    "        return df_nuevos\n",
    "\n",
    "    except Exception as e:\n",
    "        fuentes.append('db_dwh_corporativo.extract_rr_ventas_ins')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(seleccionCamposinstaladasrr.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        insertarErroresDB()\n",
    "        salidaLogMonitoreo()\n",
    "        raise e  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d03b84d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cantidad de registros descargados para instaladas rr: 9586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AMD_INTCOM\\AppData\\Local\\Temp\\ipykernel_19248\\3114088062.py:18: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_tabla_bd = pd.read_sql(sql_consulta, engine)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Configuración del logging, generación del UUID de ejecución y consulta a la base de datos\n",
    "        configurarLogging()\n",
    "        id_ejecucion = generate_uuid().upper()\n",
    "        fecha_inicio = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        fecha_inicio_date = datetime.strptime(fecha_inicio, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        df_resultado_instaladas_rr = ejecutarConsultaOdbc()\n",
    "        \n",
    "        if df_resultado_instaladas_rr is not None:\n",
    "            registros = len(df_resultado_instaladas_rr)\n",
    "        \n",
    "            if registros > 0:\n",
    "                # Realiza la selección de campos y agrega información adicional\n",
    "                df_base = seleccionCamposinstaladasrr(df_resultado_instaladas_rr, fecha_inicio_date, id_ejecucion)         \n",
    "        \n",
    "                if df_base is not None:\n",
    "                    \n",
    "                    conteo_cargue = len(df_base)\n",
    "                    df_resumen = cargueResumen(id_ejecucion, fecha_inicio_date, 'db_dwh_corporativo.extract_rr_ventas_ins', conteo_cargue, 'tb_datos_crudos_denodo_instaladas_rr', 1)\n",
    "                    cargueDatosBD(df_base)\n",
    "                    cantidad_registros.append(conteo_cargue)\n",
    "                    fuentes.append('db_dwh_corporativo.extract_rr_ventas_ins')\n",
    "                    \n",
    "                \n",
    "        fecha_fin = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        fecha_fin_date = datetime.strptime(fecha_fin, \"%Y-%m-%d %H:%M:%S\")\n",
    "        duracion_proceso = fecha_fin_date - fecha_inicio_date\n",
    "        duracion_proceso_seg = int(duracion_proceso.total_seconds())\n",
    "        actualizarFechaFinProcesamiento(id_ejecucion, fecha_fin_date, duracion_proceso_seg)\n",
    "        duracion.append(str(duracion_proceso))\n",
    "        estado.append(1)\n",
    "        salidaLogMonitoreo()\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        fuentes.append('db_dwh_corporativo.extract_rr_ventas_dig')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(\"__main__\")\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        insertarErroresDB()\n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "dev-empresas-negocios-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
