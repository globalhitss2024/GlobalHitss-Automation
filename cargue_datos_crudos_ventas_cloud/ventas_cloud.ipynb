{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl as opn\n",
    "import psycopg2\n",
    "from psycopg2 import sql, Error, OperationalError\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "import os\n",
    "import shutil  # Para mover el archivo descargado\n",
    "import logging\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "import sys\n",
    "import ast\n",
    "sys.path.append('C:\\\\Users\\\\46196682\\\\.conda\\\\envs\\\\Empresas-Negocios-webscraping\\\\Parametros')\n",
    "#C:\\\\Users\\\\46196682\\\\.conda\\\\envs\\\\Empresas-Negocios-webscraping\\\\Parametros\n",
    "import parametros_desarrollo as par\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Ruta al archivo Excel\n",
    "ruta_excel = r'C:\\\\Users\\\\46196682\\\\.conda\\\\envs\\\\\\\\Empresas-Negocios-webscraping\\\\Archivos Base\\\\Ventas_cloud.xlsx'\n",
    "#C:\\\\Users\\\\46196682\\\\.conda\\\\envs\\\\Empresas-Negocios-webscraping\\\\BASE ASIGNACION EMPRESAS.xlsx\n",
    "#C:\\\\Users\\\\46196682\\\\Documents\\\\\\\\-m venv dev-empresas-negocios-webscraping-env\\\\BASE ASIGNACION EMPRESAS.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VARIABLES GLOBALES\n",
    "fecha_actual = datetime.today().date()\n",
    "duracion = []\n",
    "fuentes = []\n",
    "cantidad_registros = []\n",
    "estado = []\n",
    "fecha_fin_procesamiento =[]\n",
    "funcion_error = []\n",
    "descripcion_error = []\n",
    "id_ejecucion = str(uuid.uuid4())  # Generar UUID de ejecución\n",
    "destino = 'Ventas Manuales Cloud'\n",
    "id_estado = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def salidaLogMonitoreo():\n",
    "    \n",
    "    Este metodo captura la informacion que se desea imprimir en el Log\n",
    "    para monitoreo y funcionamiento del desarrollo\n",
    "    Argumentos:\n",
    "        None\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        None\n",
    "    \n",
    "    Fecha_fin = datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "    print(f\"Fecha_inicio: {fecha_inicio}\")\n",
    "    print(f\"Fecha_fin: {Fecha_fin}\")\n",
    "    print(f\"Duracion: {duracion}\")\n",
    "    print(f\"Fuentes: {fuentes}\")\n",
    "    print(f\"Cantidad_registros: {cantidad_registros}\")\n",
    "    print(f\"Destino: {destino}\")\n",
    "    print(f\"Estado: {estado}\")\n",
    "    print(\"Lugar errores: \", ' | '.join(map(str, funcion_error)))\n",
    "    print(\"Descripción errores: \", ' | '.join(map(str, descripcion_error)))\n",
    "    if estado[0] == 1 :\n",
    "        print(\"Ejecución exitosa\")\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "\n",
    "\"\"\"\n",
    "def salidaLogMonitoreo():\n",
    "    \"\"\"\n",
    "    Este método captura la información que se desea imprimir en el Log\n",
    "    para monitoreo y funcionamiento del desarrollo.\n",
    "    \"\"\"\n",
    "    Fecha_fin = datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "    logging.info(f\"Fecha_inicio: {fecha_inicio}\")\n",
    "    logging.info(f\"Fecha_fin: {Fecha_fin}\")\n",
    "    logging.info(f\"Duracion: {duracion}\")\n",
    "    logging.info(f\"Fuentes: {fuentes}\")\n",
    "    logging.info(f\"Cantidad_registros: {cantidad_registros}\")\n",
    "    logging.info(f\"Destino: {destino}\")\n",
    "    logging.info(f\"Estado: {estado}\")\n",
    "    logging.info(\"Lugar errores: \" + ' | '.join(map(str, funcion_error)))\n",
    "    logging.info(\"Descripción errores: \" + ' | '.join(map(str, descripcion_error)))\n",
    "    if estado[0] == 1:\n",
    "        logging.info(\"Ejecución exitosa\")\n",
    "    logging.info(\"------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para cargar resumen de datos en la BD\n",
    "def cargueResumen(id_ejecucion, fecha_inicio_date,fecha_fin_procesamiento, duracion,fuentes, cantidad_registros, destino, id_estado):\n",
    "    try:\n",
    "        df_resumen_cargue = pd.DataFrame({\n",
    "        'id_ejecucion': [id_ejecucion],  # Envolver en una lista\n",
    "        'fecha_inicio_procesamiento': [fecha_inicio_date],\n",
    "        'fecha_fin_procesamiento': [fecha_fin_procesamiento], \n",
    "        'duracion_segundos': [duracion],\n",
    "        'fuentes': [fuentes],\n",
    "        'cantidad_registros': [cantidad_registros],\n",
    "        'destino': [destino],\n",
    "        'id_estado': [id_estado],\n",
    "    })\n",
    "        Usuario_pro = 'postgres'\n",
    "        contraseña_pro = '1Nt3l163nC14_C0m3rc14L'\n",
    "        conexion = create_engine(f'postgresql://{Usuario_pro}:{par.contrasena}@{par.host}:{par.port}/{par.bd_inteligencia_comercial}')\n",
    "        # Especificar el esquema y la tabla en la que deseas insertar los datos\n",
    "        nombre_esquema = 'control_procesamiento'\n",
    "        nombre_tabla = 'tb_resumen_cargue'\n",
    "        \n",
    "        df_resumen_cargue.to_sql(nombre_tabla, con=conexion, schema=nombre_esquema, if_exists='append', index=False)\n",
    "    \n",
    "    except SQLAlchemyError as e:\n",
    "        fuentes.append('ventas_manuales')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(cargueResumen.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        salidaLogMonitoreo()\n",
    "    finally:\n",
    "        conexion.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configurarLogging():\n",
    "    \"\"\"\n",
    "    Configura el logging para escribir en un archivo y en la salida estándar\n",
    "    Utiliza la ruta definida en par.ruta_log para el directorio de logs.\n",
    "    \n",
    "    Argumentos:\n",
    "        None\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        None\n",
    "    \"\"\"\n",
    "    # Configuración del logging\n",
    "    log_directory = par.ruta_log  # Usa la ruta definida en config.py\n",
    "    log_file = os.path.join(log_directory, \"ventas_manuales_cloud.log\")\n",
    "\n",
    "    # Crear el directorio si no existe\n",
    "    if not os.path.exists(log_directory):\n",
    "        os.makedirs(log_directory)\n",
    "\n",
    "    # Configurar el logger\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file, mode='a'),  # 'a' para modo append\n",
    "            #logging.StreamHandler()  # Para imprimir en pantalla\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargueDatosBD(df_final):\n",
    "    \"\"\"\n",
    "    Función que se encarga de cargar los dataframes procesados hacia la base de datos\n",
    "    \n",
    "    Argumentos:\n",
    "        df_final: Contiene el dataframe que se requiere cargar a la BD\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        SQLAlchemyError as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "        conexion = create_engine(f'postgresql://{par.usuario}:{par.contrasena}@{par.host}:{par.port}/{par.bd_inteligencia_comercial}')\n",
    "        # Especificar el esquema y la tabla en la que deseas insertar los datos\n",
    "        nombre_esquema = 'fuentes_cruda'\n",
    "        nombre_tabla = 'tb_datos_crudos_ventas_manuales_cloud'\n",
    "        \n",
    "        df_final.to_sql(nombre_tabla, con=conexion, schema=nombre_esquema, if_exists='append', index=False)\n",
    "        \n",
    "    except SQLAlchemyError as e:\n",
    "        fuentes.append('Ventas Manuales Cloud')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(cargueDatosBD.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        insertarErroresDB()\n",
    "        salidaLogMonitoreo()\n",
    "    finally:\n",
    "        conexion.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertarErroresDB():\n",
    "    \"\"\"\n",
    "    Metodo para insertar a POSTGRESQL los errores capturados durante la ejecución\n",
    "    Argumentos Globales:\n",
    "        fecha_inicio: Captura la fecha en que inicio la ejecución\n",
    "        fecha_fin: Captura la fecha en que finalizo la ejecución\n",
    "        duracion: Duración del procesamiento\n",
    "        fuente: Indica la fuente de donde provienen los datos\n",
    "        cantidad_registros: Cantidad de registros por fuente\n",
    "        destino: Indica la tabla a donde se estan ingestando los datos\n",
    "        id_estado: Indica el estado del proceso definidos en la base de datos \n",
    "        funcion_error: Indica la función donde se esta presentando una falla\n",
    "        descripcion_error: Descripción del error generado\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        SQLAlchemyError as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convertir las cadenas de texto a objetos datetime\n",
    "        fecha_inicio_tr = datetime.strptime(fecha_inicio, \"%Y-%m-%d %H:%M:%S\")\n",
    "        fecha_fin = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        fecha_fin_tr = datetime.strptime(fecha_fin, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        duracion_proceso_timedelta = fecha_fin_tr - fecha_inicio_tr\n",
    "        duracion_proceso_seconds = duracion_proceso_timedelta.total_seconds()\n",
    "        \n",
    "        errores = pd.DataFrame({\n",
    "            'fecha_inicio': fecha_inicio,\n",
    "            'fecha_fin': fecha_fin,\n",
    "            'duracion': duracion_proceso_seconds,\n",
    "            'fuente': fuentes,\n",
    "            'cantidad_registros': cantidad_registros,\n",
    "            'destino': destino,\n",
    "            'id_estado': estado,\n",
    "            'funcion_error': funcion_error,\n",
    "            'descripcion_error': descripcion_error\n",
    "        })\n",
    "        \n",
    "        conexion_errores = create_engine(f'postgresql://{par.usuario}:{par.contrasena}@{par.host}:{par.port}/{par.bd_inteligencia_comercial}')\n",
    "        # Especificar el esquema y la tabla en la que deseas insertar los datos\n",
    "        nombre_esquema = 'control_procesamiento'\n",
    "        nombre_tabla = 'tb_errores_cargue'\n",
    "        errores.to_sql(nombre_tabla, con=conexion_errores, schema=nombre_esquema, if_exists='append', index=False)\n",
    "        cargueResumen(id_ejecucion_en_curso, fecha_inicio_tr,2) \n",
    "        salidaLogMonitoreo()\n",
    "\n",
    "    \n",
    "    except SQLAlchemyError as e:\n",
    "        fuentes.append('Ventas Manuales Cloud')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(insertarErroresDB.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        salidaLogMonitoreo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consultarHistoricoVentas_cloud():\n",
    "    \"\"\"\n",
    "    Función que consulta los datos historicos existentes en la base de datos de la tabla de tb_datos_crudos_legalizadas\n",
    "    \n",
    "    Argumentos:\n",
    "        None\n",
    "    Retorna: \n",
    "        df_historico_mb : Retorna el historico de los datos cargados en la BD\n",
    "    Excepciones manejadas: \n",
    "        Exception as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "    try:\n",
    "        engine = create_engine(f'postgresql://{par.usuario}:{par.contrasena}@{par.host}:{par.port}/{par.bd_inteligencia_comercial}')\n",
    "\n",
    "        #engine = conexion_BD()\n",
    "        sql_consulta = \"Select * \\\n",
    "                    from fuentes_cruda.tb_datos_crudos_ventas_manuales_cloud\"\n",
    "        df_historico_mb = pd.read_sql(sql_consulta, engine)\n",
    "    \n",
    "    \n",
    "        return df_historico_mb\n",
    "        \n",
    "    except Exception as e:\n",
    "        fuentes.append('Ventas Manuales Cloud')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(consultarHistoricoVentas_cloud.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        insertarErroresDB()\n",
    "        salidaLogMonitoreo()\n",
    "    finally:\n",
    "        engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_Ventas_manuales_cloud(ruta_excel):\n",
    "    \"\"\"\n",
    "    Funcion que se encarga de extraer los datos que vienen del archivo a cargar\n",
    "    \n",
    "    Argumentos:\n",
    "        ruta_excel: archivo de excel para el cargue en la BD\n",
    "    Retorna: \n",
    "        retorna el dataframe principal de datos a cargar ya limpiados\n",
    "    Excepciones manejadas: \n",
    "        Exception as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        df_vtas_cloud_a = pd.read_excel(ruta_excel, sheet_name='base ventas Cloud')\n",
    "        \n",
    "\n",
    "        df_vtas_cloud_a.columns = [col.lower() for col in df_vtas_cloud_a.columns]  # Convertir nombres de columnas a minúsculas\n",
    "        \n",
    "        columnas_necesarias = [\n",
    "        \"fecha de venta\", \"mes\", \"año\", \"razon social\", \"nit\",\n",
    "        \"customer id\", \"idsuscription\", \"producto\", \"no servicios\",\n",
    "        \"valor total iva incluido\", \"nombres\", \"gerencia\", \n",
    "        \"jefatura\", \"cordinación\", \"segmento de alta\", \"operacion\"\n",
    "        ]\n",
    "        \n",
    "        df_filtrado_cloud = df_vtas_cloud_a[columnas_necesarias]\n",
    "        df_filtrado_cloud.columns = df_filtrado_cloud.columns.str.replace(\" \", \"_\").str.lower()\n",
    "        return df_filtrado_cloud\n",
    "    \n",
    "    except Exception as e:\n",
    "        fuentes.append('Ventas Manuales Cloud')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(df_Ventas_manuales_cloud.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        insertarErroresDB()\n",
    "        salidaLogMonitoreo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    Programa principal que se encarga de controlar el orden en que se debe ejecutar el procesamiento \n",
    "    \n",
    "    Argumentos:\n",
    "        None\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        Exception as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        configurarLogging()\n",
    "        #Variables constantes dentro del codigo para funciones\n",
    "        \n",
    "\n",
    "        id_ejecucion = str(uuid.uuid4()).upper()  # Generar ID de ejecución\n",
    "        fecha_inicio = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        fecha_inicio_tr = datetime.strptime(fecha_inicio, \"%Y-%m-%d %H:%M:%S\")\n",
    "        fecha_fin = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        fecha_fin_tr = datetime.strptime(fecha_fin, \"%Y-%m-%d %H:%M:%S\")\n",
    "        id_estado = 1\n",
    "        estado = 1  # O el valor adecuado para el estado\n",
    "        duracion_proceso_timedelta = fecha_fin_tr - fecha_inicio_tr\n",
    "        duracion_proceso_seconds = duracion_proceso_timedelta.total_seconds()\n",
    "        fecha_base_excel = pd.to_datetime('1900-01-01')\n",
    "        #df_ParametrosDesarrollo = consultarDatosParametrosDesarrollo()   \n",
    "        #engine = conexion_BD()\n",
    "        #resultado = consulta_mb(engine)\n",
    "        #ejecutar_proceso(engine)\n",
    "        #resultado_limpio = limpiar_data_mb(resultado) \n",
    "\n",
    "        \n",
    "        df_ventasmanualescloudHis = consultarHistoricoVentas_cloud()\n",
    "        df_ventasmanualescloudHis['fecha_de_venta'] = pd.to_datetime(\n",
    "            df_ventasmanualescloudHis['fecha_de_venta'], errors='coerce'\n",
    "        )\n",
    "        df_ventasmanualescloudHis['fecha_edit'] = (df_ventasmanualescloudHis['fecha_de_venta'] - fecha_base_excel).dt.days + 2  # Sumamos 2 por el ajuste de Excel\n",
    "        df_ventasmanualescloudHis['llaveDuplihis'] = df_ventasmanualescloudHis['nit'].astype(str) + \\\n",
    "            df_ventasmanualescloudHis['fecha_edit'].astype(str) + \\\n",
    "            df_ventasmanualescloudHis['customer_id'].astype(str) + \\\n",
    "            df_ventasmanualescloudHis['producto'].astype(str)\n",
    "\n",
    "\n",
    "        df_ventas_manualescloudf = df_Ventas_manuales_cloud(ruta_excel)\n",
    "        df_ventas_manualescloudf['id_ejecucion'] = id_ejecucion  # Agregar la columna id_ejecucion con el mismo UUID en todas las fila\n",
    "        df_ventas_manualescloudf['id'] = [str(uuid.uuid4()) for _ in range(len(df_ventas_manualescloudf))]  # Agregar la columna id con un UUID único por cada fila\n",
    "        df_ventas_manualescloudf['fecha_procesamiento'] = fecha_inicio  # Agregar la columna fecha_procesamiento con la fecha y hora actual\n",
    "        df_ventas_manualescloudf['id_estado_registro'] = 1\n",
    "        df_ventas_manualescloudf.columns = [col.lower() for col in df_ventas_manualescloudf.columns]  # Convertir los nombres de las columnas a minúsculas\n",
    "        df_ventas_manualescloudf['fecha_de_venta'] = pd.to_datetime(\n",
    "            df_ventas_manualescloudf['fecha_de_venta'], errors='coerce'\n",
    "        )\n",
    "        df_ventas_manualescloudf['fecha_edit'] = (df_ventas_manualescloudf['fecha_de_venta'] - fecha_base_excel).dt.days + 2  # Sumamos 2 por el ajuste de Excel\n",
    "        df_ventas_manualescloudf['llaveDuplihis'] = df_ventas_manualescloudf['nit'].astype(str) + \\\n",
    "            df_ventas_manualescloudf['fecha_edit'].astype(str) + \\\n",
    "            df_ventas_manualescloudf['customer_id'].astype(str) + \\\n",
    "            df_ventas_manualescloudf['producto'].astype(str)\n",
    " \n",
    "\n",
    "        df_ventasmanuales_a = pd.merge(df_ventas_manualescloudf, df_ventasmanualescloudHis[['llaveDuplihis']], \n",
    "                    on=['llaveDuplihis'], \n",
    "                    how='left', \n",
    "                    indicator=True)\n",
    "        \n",
    "        df_ventasmanualesfin = df_ventasmanuales_a[df_ventasmanuales_a['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\n",
    "        df_ventasmanualesfin.drop(columns=['llaveDuplihis', 'fecha_edit'], inplace=True)\n",
    "\n",
    "        registros = len(df_ventasmanualesfin)\n",
    "        cantidad_registros.append(registros)\n",
    "\n",
    "        # Ejecucion cargue de datos ETL, se carga la funcion de CargueDatosBD, insercion a BD\n",
    "        if registros > 0:\n",
    "           df_resumen = cargueResumen(\n",
    "        id_ejecucion, fecha_inicio_tr, fecha_fin_tr, duracion_proceso_seconds,\n",
    "        'Ventas Manuales Cloud', registros, 'tb_datos_crudos_ventas_manuales_cloud', id_estado\n",
    "        )\n",
    "        cargueDatosBD(df_ventasmanualesfin)\n",
    "  \n",
    "    except Exception as e:\n",
    "        fuentes.append('Ventas Manuales Cloud')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(\"__main__\")\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        insertarErroresDB()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Empresas-Negocios-webscraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
