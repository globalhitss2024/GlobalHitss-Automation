{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl as opn\n",
    "import psycopg2\n",
    "from psycopg2 import sql, Error, OperationalError\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "import os\n",
    "import shutil  \n",
    "import logging\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "import sys\n",
    "import ast\n",
    "sys.path.append('C:\\\\ambiente_desarrollo\\\\dev-empresas-negocios-env\\\\desarrollo_notebook')\n",
    "#C:\\\\Users\\\\46196682\\\\.conda\\\\envs\\\\Empresas-Negocios-webscraping\\\\Parametros\n",
    "import parametros_desarrollo as par\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Ruta al archivo Excel\n",
    "ruta_excel = r'C:\\\\ambiente_desarrollo\\\\dev-empresas-negocios-env\\\\fuentes\\\\base_conciliaciones\\\\Conciliaciones _MB.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VARIABLES GLOBALES\n",
    "fecha_actual = datetime.today().date()\n",
    "duracion = []\n",
    "fuentes = []\n",
    "cantidad_registros = []\n",
    "estado = []\n",
    "fecha_fin_procesamiento =[]\n",
    "funcion_error = []\n",
    "descripcion_error = []\n",
    "id_ejecucion = str(uuid.uuid4())  # Generar UUID de ejecución\n",
    "destino = 'Conciliaciones'\n",
    "id_estado = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def salidaLogMonitoreo():\n",
    "    \n",
    "    Este metodo captura la informacion que se desea imprimir en el Log\n",
    "    para monitoreo y funcionamiento del desarrollo\n",
    "    Argumentos:\n",
    "        None\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        None\n",
    "    \n",
    "    Fecha_fin = datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "    print(f\"Fecha_inicio: {fecha_inicio}\")\n",
    "    print(f\"Fecha_fin: {Fecha_fin}\")\n",
    "    print(f\"Duracion: {duracion}\")\n",
    "    print(f\"Fuentes: {fuentes}\")\n",
    "    print(f\"Cantidad_registros: {cantidad_registros}\")\n",
    "    print(f\"Destino: {destino}\")\n",
    "    print(f\"Estado: {estado}\")\n",
    "    print(\"Lugar errores: \", ' | '.join(map(str, funcion_error)))\n",
    "    print(\"Descripción errores: \", ' | '.join(map(str, descripcion_error)))\n",
    "    if estado[0] == 1 :\n",
    "        print(\"Ejecución exitosa\")\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "\n",
    "\"\"\"\n",
    "def salidaLogMonitoreo():\n",
    "    \"\"\"\n",
    "    Este método captura la información que se desea imprimir en el Log\n",
    "    para monitoreo y funcionamiento del desarrollo.\n",
    "    \"\"\"\n",
    "    Fecha_fin = datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "    logging.info(f\"Fecha_inicio: {fecha_inicio}\")\n",
    "    logging.info(f\"Fecha_fin: {Fecha_fin}\")\n",
    "    logging.info(f\"Duracion: {duracion}\")\n",
    "    logging.info(f\"Fuentes: {fuentes}\")\n",
    "    logging.info(f\"Cantidad_registros: {cantidad_registros}\")\n",
    "    logging.info(f\"Destino: {destino}\")\n",
    "    logging.info(f\"Estado: {estado}\")\n",
    "    logging.info(\"Lugar errores: \" + ' | '.join(map(str, funcion_error)))\n",
    "    logging.info(\"Descripción errores: \" + ' | '.join(map(str, descripcion_error)))\n",
    "    if estado[0] == 1:\n",
    "        logging.info(\"Ejecución exitosa\")\n",
    "    logging.info(\"------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para cargar resumen de datos en la BD\n",
    "def cargueResumen(id_ejecucion, fecha_inicio_date,fecha_fin_procesamiento, duracion,fuentes, cantidad_registros, destino, id_estado):\n",
    "    try:\n",
    "        df_resumen_cargue = pd.DataFrame({\n",
    "        'id_ejecucion': [id_ejecucion],  # Envolver en una lista\n",
    "        'fecha_inicio_procesamiento': [fecha_inicio_date],\n",
    "        'fecha_fin_procesamiento': [fecha_fin_procesamiento], \n",
    "        'duracion_segundos': [duracion],\n",
    "        'fuentes': [fuentes],\n",
    "        'cantidad_registros': [cantidad_registros],\n",
    "        'destino': [destino],\n",
    "        'id_estado': [id_estado],\n",
    "    })\n",
    "\n",
    "        conexion = create_engine(f'postgresql://{par.usuario}:{par.contrasena}@{par.host}:{par.port}/{par.bd_inteligencia_comercial}')\n",
    "        # Especificar el esquema y la tabla en la que deseas insertar los datos\n",
    "        nombre_esquema = 'control_procesamiento'\n",
    "        nombre_tabla = 'tb_resumen_cargue'\n",
    "        \n",
    "        df_resumen_cargue.to_sql(nombre_tabla, con=conexion, schema=nombre_esquema, if_exists='append', index=False)\n",
    "    \n",
    "    except SQLAlchemyError as e:\n",
    "        fuentes.append('Conciliaciones')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(cargueResumen.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        salidaLogMonitoreo()\n",
    "    finally:\n",
    "        conexion.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configurarLogging():\n",
    "    \"\"\"\n",
    "    Configura el logging para escribir en un archivo y en la salida estándar\n",
    "    Utiliza la ruta definida en par.ruta_log para el directorio de logs.\n",
    "    \n",
    "    Argumentos:\n",
    "        None\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        None\n",
    "    \"\"\"\n",
    "    # Configuración del logging\n",
    "    log_directory = par.ruta_log_desarrollo  # Usa la ruta definida en config.py\n",
    "    log_file = os.path.join(log_directory, \"conciliaciones_mb.log\")\n",
    "\n",
    "    # Crear el directorio si no existe\n",
    "    if not os.path.exists(log_directory):\n",
    "        os.makedirs(log_directory)\n",
    "\n",
    "    # Configurar el logger\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file, mode='a'),  # 'a' para modo append\n",
    "            #logging.StreamHandler()  # Para imprimir en pantalla\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargueDatosBD(df_final):\n",
    "    \"\"\"\n",
    "    Función que se encarga de cargar los dataframes procesados hacia la base de datos\n",
    "    \n",
    "    Argumentos:\n",
    "        df_final: Contiene el dataframe que se requiere cargar a la BD\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        SQLAlchemyError as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "        conexion = create_engine(f'postgresql://{par.usuario}:{par.contrasena}@{par.host}:{par.port}/{par.bd_inteligencia_comercial_desarrollo}')\n",
    "        # Especificar el esquema y la tabla en la que deseas insertar los datos\n",
    "        nombre_esquema = 'fuentes_cruda'\n",
    "        nombre_tabla = 'tb_datos_crudos_conciliaciones_mb'\n",
    "        \n",
    "        df_final.to_sql(nombre_tabla, con=conexion, schema=nombre_esquema, if_exists='append', index=False)\n",
    "        \n",
    "    except SQLAlchemyError as e:\n",
    "        fuentes.append('Conciliaciones')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(cargueDatosBD.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        insertarErroresDB()\n",
    "        salidaLogMonitoreo()\n",
    "    finally:\n",
    "        conexion.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertarErroresDB():\n",
    "    \"\"\"\n",
    "    Metodo para insertar a POSTGRESQL los errores capturados durante la ejecución\n",
    "    Argumentos Globales:\n",
    "        fecha_inicio: Captura la fecha en que inicio la ejecución\n",
    "        fecha_fin: Captura la fecha en que finalizo la ejecución\n",
    "        duracion: Duración del procesamiento\n",
    "        fuente: Indica la fuente de donde provienen los datos\n",
    "        cantidad_registros: Cantidad de registros por fuente\n",
    "        destino: Indica la tabla a donde se estan ingestando los datos\n",
    "        id_estado: Indica el estado del proceso definidos en la base de datos \n",
    "        funcion_error: Indica la función donde se esta presentando una falla\n",
    "        descripcion_error: Descripción del error generado\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        SQLAlchemyError as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convertir las cadenas de texto a objetos datetime\n",
    "        fecha_inicio_tr = datetime.strptime(fecha_inicio, \"%Y-%m-%d %H:%M:%S\")\n",
    "        fecha_fin = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        fecha_fin_tr = datetime.strptime(fecha_fin, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        duracion_proceso_timedelta = fecha_fin_tr - fecha_inicio_tr\n",
    "        duracion_proceso_seconds = duracion_proceso_timedelta.total_seconds()\n",
    "        \n",
    "        errores = pd.DataFrame({\n",
    "            'fecha_inicio': fecha_inicio,\n",
    "            'fecha_fin': fecha_fin,\n",
    "            'duracion': duracion_proceso_seconds,\n",
    "            'fuente': fuentes,\n",
    "            'cantidad_registros': cantidad_registros,\n",
    "            'destino': destino,\n",
    "            'id_estado': estado,\n",
    "            'funcion_error': funcion_error,\n",
    "            'descripcion_error': descripcion_error\n",
    "        })\n",
    "        \n",
    "        conexion_errores = create_engine(f'postgresql://{par.usuario}:{par.contrasena}@{par.host}:{par.port}/{par.bd_inteligencia_comercial_desarrollo}')\n",
    "        # Especificar el esquema y la tabla en la que deseas insertar los datos\n",
    "        nombre_esquema = 'control_procesamiento'\n",
    "        nombre_tabla = 'tb_errores_cargue'\n",
    "        errores.to_sql(nombre_tabla, con=conexion_errores, schema=nombre_esquema, if_exists='append', index=False)\n",
    "        cargueResumen(id_ejecucion_en_curso, fecha_inicio_tr,2) \n",
    "        salidaLogMonitoreo()\n",
    "\n",
    "    \n",
    "    except SQLAlchemyError as e:\n",
    "        fuentes.append('Conciliaciones')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(insertarErroresDB.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        salidaLogMonitoreo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consultarHistoricoConciliaciones():\n",
    "    \"\"\"\n",
    "    Función que consulta los datos historicos existentes en la base de datos de la tabla de tb_datos_crudos_legalizadas\n",
    "    \n",
    "    Argumentos:\n",
    "        None\n",
    "    Retorna: \n",
    "        df_historico_mb : Retorna el historico de los datos cargados en la BD\n",
    "    Excepciones manejadas: \n",
    "        Exception as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "    try:\n",
    "        engine = create_engine(f'postgresql://{par.usuario}:{par.contrasena}@{par.host}:{par.port}/{par.bd_inteligencia_comercial_desarrollo}')\n",
    "\n",
    "        #engine = conexion_BD()\n",
    "        sql_consulta = \"Select * \\\n",
    "                    from fuentes_cruda.tb_datos_crudos_conciliaciones_mb\"\n",
    "        df_historico_mb = pd.read_sql(sql_consulta, engine)\n",
    "    \n",
    "    \n",
    "        return df_historico_mb\n",
    "        \n",
    "    except Exception as e:\n",
    "        fuentes.append('Conciliaciones')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(consultarHistoricoConciliaciones.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        insertarErroresDB()\n",
    "        salidaLogMonitoreo()\n",
    "    finally:\n",
    "        engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_Conciliaciones(ruta_excel):\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Leer el archivo Excel y especificar la hoja\n",
    "        df_asignacion_bajas = pd.read_excel(ruta_excel, sheet_name='Paq_Datos_Marca_Blanca')\n",
    "        \n",
    "        # Verifica si la columna 'NIT' existe en el Excel\n",
    "        if 'NIT' not in df_asignacion_bajas.columns:\n",
    "            print(\"La columna 'NIT' no se encuentra en el archivo Excel.\")\n",
    "            return None\n",
    "        df_asignacion_bajas.columns = [col.lower() for col in df_asignacion_bajas.columns]  # Convertir nombres de columnas a minúsculas\n",
    "        \n",
    "        \n",
    "        return df_asignacion_bajas\n",
    "    \n",
    "    except Exception as e:\n",
    "        fuentes.append('Conciliaciones')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(df_Conciliaciones.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        insertarErroresDB()\n",
    "        salidaLogMonitoreo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        configurarLogging()\n",
    "        #Variables constantes dentro del codigo para funciones\n",
    "        \n",
    "\n",
    "        id_ejecucion = str(uuid.uuid4()).upper()  # Generar ID de ejecución\n",
    "        fecha_inicio = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        fecha_inicio_tr = datetime.strptime(fecha_inicio, \"%Y-%m-%d %H:%M:%S\")\n",
    "        fecha_fin = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        fecha_fin_tr = datetime.strptime(fecha_fin, \"%Y-%m-%d %H:%M:%S\")\n",
    "        id_estado = 1\n",
    "        estado = 1  # O el valor adecuado para el estado\n",
    "        duracion_proceso_timedelta = fecha_fin_tr - fecha_inicio_tr\n",
    "        duracion_proceso_seconds = duracion_proceso_timedelta.total_seconds()\n",
    "        fecha_base_excel = pd.to_datetime('1900-01-01')\n",
    "        #df_ParametrosDesarrollo = consultarDatosParametrosDesarrollo()   \n",
    "        #engine = conexion_BD()\n",
    "        #resultado = consulta_mb(engine)\n",
    "        #ejecutar_proceso(engine)\n",
    "        #resultado_limpio = limpiar_data_mb(resultado) \n",
    "\n",
    "        \n",
    "        df_conciliacionesHis = consultarHistoricoConciliaciones()\n",
    "        df_conciliacionesHis['fecha_desact_paq'] = pd.to_datetime(\n",
    "            df_conciliacionesHis['fecha_desact_paq'], errors='coerce'\n",
    "        )\n",
    "        df_conciliacionesHis['fecha_desac_paq_excel'] = (df_conciliacionesHis['fecha_desact_paq'] - fecha_base_excel).dt.days + 2  # Sumamos 2 por el ajuste de Excel\n",
    "        df_conciliacionesHis['llaveDuplihis'] = df_conciliacionesHis['customer_id'].astype(str) + \\\n",
    "            df_conciliacionesHis['fecha_desac_paq_excel'].astype(str) + \\\n",
    "            df_conciliacionesHis['valor_paq'].astype(str) + \\\n",
    "            df_conciliacionesHis['desc_serv_instalado'].astype(str)\n",
    "\n",
    "\n",
    "        df_conciliaciones_mb = df_Conciliaciones(ruta_excel)\n",
    "        df_conciliaciones_mb['id_ejecucion'] = id_ejecucion  # Agregar la columna id_ejecucion con el mismo UUID en todas las fila\n",
    "        df_conciliaciones_mb['id'] = [str(uuid.uuid4()) for _ in range(len(df_conciliaciones_mb))]  # Agregar la columna id con un UUID único por cada fila\n",
    "        df_conciliaciones_mb['fecha_procesamiento'] = fecha_inicio  # Agregar la columna fecha_procesamiento con la fecha y hora actual\n",
    "        df_conciliaciones_mb['id_estado'] = 1  # Crear el estado del registro como entero\n",
    "        df_conciliaciones_mb['id_estado_registro'] = 1\n",
    "        df_conciliaciones_mb.columns = [col.lower() for col in df_conciliaciones_mb.columns]  # Convertir los nombres de las columnas a minúsculas\n",
    "        df_conciliaciones_mb['fecha_desact_paq'] = pd.to_datetime(\n",
    "            df_conciliaciones_mb['fecha_desact_paq'], errors='coerce'\n",
    "        )\n",
    "        df_conciliaciones_mb['fecha_desac_paq_excel'] = (df_conciliaciones_mb['fecha_desact_paq'] - fecha_base_excel).dt.days + 2  # Sumamos 2 por el ajuste de Excel\n",
    "        df_conciliaciones_mb['llaveDuplihis'] = df_conciliaciones_mb['customer_id'].astype(str) + \\\n",
    "            df_conciliaciones_mb['fecha_desac_paq_excel'].astype(str) + \\\n",
    "            df_conciliaciones_mb['valor_paq'].astype(str) + \\\n",
    "            df_conciliaciones_mb['desc_serv_instalado'].astype(str)\n",
    " \n",
    "\n",
    "        df_concilicacionesfin_a = pd.merge(df_conciliaciones_mb, df_conciliacionesHis[['llaveDuplihis']], \n",
    "                    on=['llaveDuplihis'], \n",
    "                    how='left', \n",
    "                    indicator=True)\n",
    "        \n",
    "        df_concilicacionesfin = df_concilicacionesfin_a[df_concilicacionesfin_a['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "        \n",
    "\n",
    "        df_conciliacionesHis.drop(columns=['llaveDuplihis', 'fecha_desac_paq_excel'], inplace=True)\n",
    "        df_conciliaciones_mb.drop(columns=['llaveDuplihis', 'fecha_desac_paq_excel'], inplace=True)\n",
    "        df_concilicacionesfin.drop(columns=['llaveDuplihis', 'fecha_desac_paq_excel'], inplace=True)\n",
    "\n",
    "        registros = len(df_concilicacionesfin)\n",
    "        cantidad_registros.append(registros)\n",
    "\n",
    "        # Ejecucion cargue de datos ETL, se carga la funcion de CargueDatosBD, insercion a BD\n",
    "        if registros > 0:\n",
    "           df_resumen = cargueResumen(\n",
    "        id_ejecucion, fecha_inicio_tr, fecha_fin_tr, duracion_proceso_seconds,\n",
    "        'Conciliaciones_Mb', registros, 'tb_datos_crudos_conciliaciones_mb', id_estado\n",
    "        )\n",
    "        cargueDatosBD(df_concilicacionesfin)\n",
    "  \n",
    "    except Exception as e:\n",
    "        fuentes.append('Conciliaciones')\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(\"__main__\")\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        insertarErroresDB()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-empresas-negocios-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
