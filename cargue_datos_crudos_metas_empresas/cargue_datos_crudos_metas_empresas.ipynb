{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n***************************************************************************************\\n* CLARO  HITSS - EMPRESAS Y NEGOCIOS                                                  *\\n* OBJETIVO: Extración de fuentes crudas de Metas (Carmen Bejarano)                    * \\n*           y cargue a base de datos de forma automatica                              *\\n*           Comunicacion Celular S.A.- Comcel S.A\\\\Wilmer Camargo Ochoa - Data_PCC     *\\n* TABLA DE INGESTA POSTGRESQL: tb_datos_crudos_metas_oficial                          *\\n* FECHA CREACION: 30 de Diciembre de 2024                                             *\\n* ELABORADO POR: Danilo Rodríguez                                                     *\\n* *************************************************************************************\\n* MODIFICACIONES\\n* NOMBRE                   FECHA      VERSION            DESCRIPCION\\n* \\n*\\n***************************************************************************************\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "***************************************************************************************\n",
    "* CLARO  HITSS - EMPRESAS Y NEGOCIOS                                                  *\n",
    "* OBJETIVO: Extración de fuentes crudas de Metas (Carmen Bejarano)                    * \n",
    "*           y cargue a base de datos de forma automatica                              *\n",
    "*           Comunicacion Celular S.A.- Comcel S.A\\Wilmer Camargo Ochoa - Data_PCC     *\n",
    "* TABLA DE INGESTA POSTGRESQL: tb_datos_crudos_metas_oficial                          *\n",
    "* FECHA CREACION: 30 de Diciembre de 2024                                             *\n",
    "* ELABORADO POR: Danilo Rodríguez                                                     *\n",
    "* *************************************************************************************\n",
    "* MODIFICACIONES\n",
    "* NOMBRE                   FECHA      VERSION            DESCRIPCION\n",
    "* \n",
    "*\n",
    "***************************************************************************************\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib3\n",
    "urllib3.disable_warnings()\n",
    "from datetime import datetime\n",
    "import sys\n",
    "sys.path.append('C:/ambiente_desarrollo/dev-empresas-negocios-env/desarrollo_notebook')\n",
    "import parametros_desarrollo as par\n",
    "import uuid\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "import os\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import logging\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "pd.set_option('display.max_columns', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VARIABLES GLOBALES\n",
    "fecha_inicio = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "fecha_actual = datetime.today().date()\n",
    "duracion = []\n",
    "fuentes = []\n",
    "cantidad_registros = []\n",
    "destino = [par.destino_metas_empresas]\n",
    "estado = []\n",
    "funcion_error = []\n",
    "descripcion_error = []\n",
    "id_ejecucion_en_curso = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef salidaLogMonitoreo():\\n    Este método captura la información que se desea imprimir en el Log\\n    para monitoreo y funcionamiento del desarrollo.\\n    Fecha_fin = datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\\n    logging.info(f\"Fecha_inicio: {fecha_inicio}\")\\n    logging.info(f\"Fecha_fin: {Fecha_fin}\")\\n    logging.info(f\"Duracion: {duracion}\")\\n    logging.info(f\"Fuentes: {fuentes}\")\\n    logging.info(f\"Cantidad_registros: {cantidad_registros}\")\\n    logging.info(f\"Destino: {destino}\")\\n    logging.info(f\"Estado: {estado}\")\\n    logging.info(\"Lugar errores: \" + \\' | \\'.join(map(str, funcion_error)))\\n    logging.info(\"Descripción errores: \" + \\' | \\'.join(map(str, descripcion_error)))\\n    if estado[0] == 1:\\n        logging.info(\"Ejecución exitosa\")\\n    logging.info(\"------------------------------------------------------------------\")\\n '"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def salidaLogMonitoreo():\n",
    "    \"\"\"\n",
    "    Este metodo captura la informacion que se desea imprimir en el Log\n",
    "    para monitoreo y funcionamiento del desarrollo\n",
    "    Argumentos:\n",
    "        None\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        None\n",
    "    \"\"\"\n",
    "    Fecha_fin = datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "    print(f\"Fecha_inicio: {fecha_inicio}\")\n",
    "    print(f\"Fecha_fin: {Fecha_fin}\")\n",
    "    print(f\"Duracion: {duracion}\")\n",
    "    print(f\"Fuentes: {fuentes}\")\n",
    "    print(f\"Cantidad_registros: {cantidad_registros}\")\n",
    "    print(f\"Destino: {destino}\")\n",
    "    print(f\"Estado: {estado}\")\n",
    "    print(\"Lugar errores: \", ' | '.join(map(str, funcion_error)))\n",
    "    print(\"Descripción errores: \", ' | '.join(map(str, descripcion_error)))\n",
    "    if estado[0] == 1 :\n",
    "        print(\"Ejecución exitosa\")\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "\n",
    "\"\"\"\n",
    "def salidaLogMonitoreo():\n",
    "    Este método captura la información que se desea imprimir en el Log\n",
    "    para monitoreo y funcionamiento del desarrollo.\n",
    "    Fecha_fin = datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "    logging.info(f\"Fecha_inicio: {fecha_inicio}\")\n",
    "    logging.info(f\"Fecha_fin: {Fecha_fin}\")\n",
    "    logging.info(f\"Duracion: {duracion}\")\n",
    "    logging.info(f\"Fuentes: {fuentes}\")\n",
    "    logging.info(f\"Cantidad_registros: {cantidad_registros}\")\n",
    "    logging.info(f\"Destino: {destino}\")\n",
    "    logging.info(f\"Estado: {estado}\")\n",
    "    logging.info(\"Lugar errores: \" + ' | '.join(map(str, funcion_error)))\n",
    "    logging.info(\"Descripción errores: \" + ' | '.join(map(str, descripcion_error)))\n",
    "    if estado[0] == 1:\n",
    "        logging.info(\"Ejecución exitosa\")\n",
    "    logging.info(\"------------------------------------------------------------------\")\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conexion_BD():\n",
    "    \"\"\"\n",
    "    Función que genera la conexión hacia la base de datos por medio de la libreria psycopg2\n",
    "    \n",
    "    Argumentos:\n",
    "        None\n",
    "    Retorna: \n",
    "        conn: Conexion con la base de datos\n",
    "    Excepciones manejadas: \n",
    "        SQLAlchemyError as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            host= par.host,\n",
    "            port= par.port,\n",
    "            dbname= par.bd_inteligencia_comercial,\n",
    "            user= par.usuario,\n",
    "            password= par.contrasena\n",
    "        )\n",
    "        return conn\n",
    "    \n",
    "    except SQLAlchemyError as e:\n",
    "        fuentes.append(par.nombre_archivo_metas_empresas)\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(conexion_BD.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        salidaLogMonitoreo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertarErroresDB():\n",
    "    \"\"\"\n",
    "    Metodo para insertar a POSTGRESQL los errores capturados durante la ejecución\n",
    "    Argumentos Globales:\n",
    "        fecha_inicio: Captura la fecha en que inicio la ejecución\n",
    "        fecha_fin: Captura la fecha en que finalizo la ejecución\n",
    "        duracion: Duración del procesamiento\n",
    "        fuente: Indica la fuente de donde provienen los datos\n",
    "        cantidad_registros: Cantidad de registros por fuente\n",
    "        destino: Indica la tabla a donde se estan ingestando los datos\n",
    "        id_estado: Indica el estado del proceso definidos en la base de datos \n",
    "        funcion_error: Indica la función donde se esta presentando una falla\n",
    "        descripcion_error: Descripción del error generado\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        SQLAlchemyError as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convertir las cadenas de texto a objetos datetime\n",
    "        fecha_inicio_tr = datetime.strptime(fecha_inicio, \"%Y-%m-%d %H:%M:%S\")\n",
    "        fecha_fin = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        fecha_fin_tr = datetime.strptime(fecha_fin, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        duracion_proceso_timedelta = fecha_fin_tr - fecha_inicio_tr\n",
    "        duracion_proceso_seconds = duracion_proceso_timedelta.total_seconds()\n",
    "        \n",
    "        errores = pd.DataFrame({\n",
    "            'fecha_inicio': fecha_inicio,\n",
    "            'fecha_fin': fecha_fin,\n",
    "            'duracion': duracion_proceso_seconds,\n",
    "            'fuente': fuentes,\n",
    "            'cantidad_registros': cantidad_registros,\n",
    "            'destino': destino,\n",
    "            'id_estado': estado,\n",
    "            'funcion_error': funcion_error,\n",
    "            'descripcion_error': descripcion_error\n",
    "        })\n",
    "        \n",
    "        conexion_errores = create_engine(f'postgresql://{par.usuario}:{par.contrasena}@{par.host}:{par.port}/{par.bd_inteligencia_comercial}')\n",
    "        # Especificar el esquema y la tabla en la que deseas insertar los datos\n",
    "        nombre_esquema = 'control_procesamiento'\n",
    "        nombre_tabla = 'tb_errores_cargue'\n",
    "        errores.to_sql(nombre_tabla, con=conexion_errores, schema=nombre_esquema, if_exists='append', index=False)\n",
    "        cargueResumen(id_ejecucion_en_curso, fecha_inicio_tr,par.nombre_archivo_metas_empresas,0,par.destino_metas_empresas,2) \n",
    "        salidaLogMonitoreo()\n",
    "\n",
    "    except SQLAlchemyError as e:\n",
    "        fuentes.append(par.ruta_fuente_metas_empresas)\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(insertarErroresDB.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        salidaLogMonitoreo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actualizarFechaFinProcesamiento(id_ejecucion, fecha_fin_date, duracion_proceso_seg):\n",
    "    \"\"\"\n",
    "    Función que actualiza la fecha fin de procesamiento y duración para el proceso que se ejecuto.\n",
    "    Utilizando cursores\n",
    "    \n",
    "    Argumentos:\n",
    "        id_ejecucion: id del proceso ejecutado\n",
    "        fecha_fin_date: Fecha fin de procesamiento\n",
    "        duracion_proceso_seg: Duración en segundos del procesamiento\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        Exception as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        \n",
    "        conn = conexion_BD()\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        update_query = \"\"\"\n",
    "            UPDATE control_procesamiento.tb_resumen_cargue \n",
    "            SET fecha_fin_procesamiento = %s,\n",
    "            duracion_segundos = %s\n",
    "            WHERE id_ejecucion = %s\n",
    "        \"\"\"\n",
    "        cur.execute(update_query, (fecha_fin_date, duracion_proceso_seg, id_ejecucion))\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        fuentes.append(par.nombre_archivo_metas_empresas)\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(actualizarFechaFinProcesamiento.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        insertarErroresDB()\n",
    "        salidaLogMonitoreo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_uuid():\n",
    "    \"\"\"\n",
    "    Función que genera un numero alfanumerico para creación de llaves primarias y foraneas\n",
    "    \n",
    "    Argumentos:\n",
    "        None\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        Exception as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        return str(uuid.uuid4())\n",
    "    \n",
    "    except Exception as e:\n",
    "        fuentes.append(par.nombre_archivo_metas_empresas)\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(generate_uuid.__name__)\n",
    "        insertarErroresDB()\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        salidaLogMonitoreo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def archivo_modificado_hoy(ruta_archivo):\n",
    "    \"\"\"\n",
    "    Función que indica la fecha de actualización de las fuentes\n",
    "    \n",
    "    Argumentos:\n",
    "        ruta_archivo: Contiene la ruta donde se encuentran los archivos fuente\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        Exception as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        fecha_modificacion = datetime.fromtimestamp(os.path.getmtime(ruta_archivo)).date()\n",
    "        return fecha_modificacion == fecha_actual\n",
    "    \n",
    "    except Exception as e:\n",
    "        fuentes.append(par.nombre_archivo_metas_empresas)\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(archivo_modificado_hoy.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        insertarErroresDB()\n",
    "        salidaLogMonitoreo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importarMetasEmpresas(ruta, hoja_calculo_metas_empresas):\n",
    "    \"\"\"\n",
    "    Este metodo realiza la importacion de las metas oficial de la fuente cruda\n",
    "    Argumentos:\n",
    "        ruta: ruta donde se encuentra el archivo\n",
    "        hoja_calculo_metas_oficial: nombre de la hoja de calculo del canal fijo\n",
    "    Retorna: \n",
    "        base_excel_metas_oficial: dataframe con los datos de la fuente cruda\n",
    "    Excepciones manejadas:\n",
    "        Exception as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Lista los archivos de la ruta\n",
    "        files = os.listdir(ruta)\n",
    "\n",
    "        # Unir la ruta con el nombre del archivo para obtener la ruta completa\n",
    "        full_paths = [os.path.join(ruta, file) for file in files]\n",
    "\n",
    "        # Obtener el archivo más reciente de la ruta\n",
    "        newest_file = max(full_paths, key=os.path.getctime)\n",
    "    \n",
    "        base_excel_metas_empresas = pd.read_excel(newest_file, sheet_name=hoja_calculo_metas_empresas)\n",
    "        return base_excel_metas_empresas\n",
    "    \n",
    "    except Exception as e:\n",
    "        fuentes.append(par.nombre_archivo_metas_empresas)\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(importarMetasEmpresas.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        insertarErroresDB()\n",
    "        salidaLogMonitoreo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seleccionCamposMetasEmpresas(df_excel, fecha_inicio_date, id_ejecucion):\n",
    "    \"\"\"\n",
    "    Función que se encarga de añadir campos necesarios o faltantes para el cargue a la base de datos\n",
    "\n",
    "    Argumentos:\n",
    "        df_combinado: Contiene el dataframe que se requiere para añadir los campos\n",
    "        fecha_inicio_date: Fecha de inicio de procesamiento\n",
    "        id_ejecucion: ID de ejecucion\n",
    "    Retorna: \n",
    "        df_base: Retorna el dataframe con los campos faltantes\n",
    "    Excepciones manejadas: \n",
    "        Exception as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "    try:    \n",
    "        df_excel.columns = df_excel.columns.str.strip()\n",
    "        df_excel.columns = df_excel.columns.str.upper()\n",
    "\n",
    "        df_base = df_excel[['TIPO', 'CÉDULA', 'NOMBRE', 'CARGO', 'NOMBRE GERENTE', 'DIRECTOR',\n",
    "                   'ALTAS MÓVIL', 'BAJAS MÓVIL', 'CAMBIO DE PLAN', 'RETO ESTRATÉGICO MÓVIL', 'NETO MÓVIL',\n",
    "                   'INCENTIVO UNIDADES MÓVIL', 'LÍNEAS BAJAS', 'LÍNEAS NETAS']].copy()\n",
    "    \n",
    "        df_base['id'] = [uuid.uuid4() for _ in range(len(df_base))]\n",
    "        df_base['id_ejecucion'] = id_ejecucion\n",
    "        df_base['fecha_procesamiento'] = fecha_inicio_date\n",
    "        df_base['fuente'] = par.nombre_archivo_metas_empresas\n",
    "        df_base['id_estado_registro'] = 1\n",
    "    \n",
    "        df_base = df_base.rename(columns ={\n",
    "            'TIPO' : 'tipo',\n",
    "            'CÉDULA': 'identificacion', \n",
    "            'NOMBRE': 'nombre',\n",
    "            'CARGO': 'cargo',\n",
    "            'NOMBRE GERENTE': 'nombre_gerente',\n",
    "            'DIRECTOR': 'director',\n",
    "            'ALTAS MÓVIL': 'altas_movil',\n",
    "            'BAJAS MÓVIL': 'bajas_movil',\n",
    "            'CAMBIO DE PLAN': 'cambio_plan',\n",
    "            'RETO ESTRATÉGICO MÓVIL': 'reto_estrategico_movil',\n",
    "            'NETO MÓVIL': 'neto_movil',\n",
    "            'INCENTIVO UNIDADES MÓVIL': 'incentivo_unidades_movil',\n",
    "            'LÍNEAS BAJAS': 'lineas_bajas',\n",
    "            'LÍNEAS NETAS': 'lineas_netas'\n",
    "\n",
    "        })\n",
    "\n",
    "        df_base = df_base[['id','id_ejecucion', 'tipo', 'identificacion', 'nombre', 'cargo', 'nombre_gerente', 'director', 'altas_movil', 'bajas_movil', 'cambio_plan', 'reto_estrategico_movil', 'neto_movil','incentivo_unidades_movil','lineas_bajas','lineas_netas', 'fecha_procesamiento', 'fuente', 'id_estado_registro']]\n",
    "        return df_base\n",
    "    \n",
    "    except Exception as e:\n",
    "        fuentes.append(par.nombre_archivo_metas_oficial)\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(seleccionCamposMetasEmpresas.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        insertarErroresDB()\n",
    "        salidaLogMonitoreo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargueDatosBD(df_final):\n",
    "    \"\"\"\n",
    "    Este metodo realiza el cargue de los datos a la base de datos\n",
    "    Argumentos:\n",
    "        df_final: dataframe con los datos de la fuente cruda\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas:\n",
    "        SQLAlchemyError as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        conexion = create_engine(f'postgresql://{par.usuario}:{par.contrasena}@{par.host}:{par.port}/{par.bd_inteligencia_comercial}')\n",
    "    \n",
    "        # Especificar el esquema y la tabla en la que deseas insertar los datos\n",
    "        nombre_esquema = 'fuentes_cruda'\n",
    "        nombre_tabla = 'tb_datos_crudos_metas_empresas'\n",
    "\n",
    "        df_final.to_sql(nombre_tabla, con = conexion, schema=nombre_esquema, if_exists='append', index=False)\n",
    "    \n",
    "    except SQLAlchemyError as e:\n",
    "        fuentes.append(par.nombre_archivo_metas_empresas)\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(cargueDatosBD.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        insertarErroresDB()\n",
    "        salidaLogMonitoreo()\n",
    "    finally:\n",
    "        conexion.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargueResumen(id_ejecucion, fecha_inicio_date,fuentes,cantidad_registros,destino,estado):\n",
    "    \"\"\"\n",
    "    Función que se encarga de cargar estadisticas de los datos que estan siendo procesados\n",
    "    \n",
    "    Argumentos:\n",
    "        id_ejecucion: Contiene un numero alfanumerico para creación de llaves primarias y foraneas de la base de datos\n",
    "        fecha_inicio_date: Fecha de inicio del procesamiento\n",
    "        fecha_fin_date: Fecha de fin del procesamiento\n",
    "        duracion_proceso: Duración del procesamiento \n",
    "        fuentes: Fuentes de donde provienen los datos\n",
    "        cantidad_registros: Cantidad de registros procesados\n",
    "        destino: Tabla donde se ingestan los datos\n",
    "        estado: Indica el estado del proceso de acuerdo a lo definido en la base de datos en la tabla control_procesamiento.estados_cargue \n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        SQLAlchemyError as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        \n",
    "        df_resumen_cargue = pd.DataFrame({\n",
    "            'id_ejecucion': id_ejecucion,\n",
    "            'fecha_inicio_procesamiento': fecha_inicio_date,\n",
    "            'fuentes': fuentes,\n",
    "            'cantidad_registros': cantidad_registros,\n",
    "            'destino': [destino],\n",
    "            'id_estado': [estado],\n",
    "        })\n",
    "\n",
    "        #errores de conexion se ponen a mano\n",
    "        conexion = create_engine(f'postgresql://{par.usuario}:{par.contrasena}@{par.host}:{par.port}/{par.bd_inteligencia_comercial}')\n",
    "        # Especificar el esquema y la tabla en la que deseas insertar los datos\n",
    "        nombre_esquema = 'control_procesamiento'\n",
    "        nombre_tabla = 'tb_resumen_cargue'\n",
    "        \n",
    "        df_resumen_cargue.to_sql(nombre_tabla, con=conexion, schema=nombre_esquema, if_exists='append', index=False)\n",
    "\n",
    "    except SQLAlchemyError as e:\n",
    "        fuentes.append(par.nombre_archivo_metas_empresas)\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(cargueResumen.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        salidaLogMonitoreo()\n",
    "    finally:\n",
    "        conexion.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cambioDeEstado():\n",
    "    \"\"\"\n",
    "    Este metodo realiza el cambio de id_estado de los cargues anteriores de metas oficial\n",
    "    Argumentos:\n",
    "        None\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas:\n",
    "        Exception as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = conexion_BD()\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        query = \"UPDATE fuentes_cruda.tb_datos_crudos_metas_empresas SET id_estado_registro = 4 WHERE id_estado_registro = 1\"\n",
    "        cursor.execute(query)\n",
    "        conn.commit()\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        fuentes.append(par.nombre_archivo_metas_empresas)\n",
    "        cantidad_registros.append(0)\n",
    "        estado.append(2)\n",
    "        funcion_error.append(cambioDeEstado.__name__)\n",
    "        descripcion_error.append(str(e)[:100])\n",
    "        salidaLogMonitoreo()\n",
    "    finally:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiezaCamposString(df):\n",
    "    for campo in df.select_dtypes(include=['object']).columns:\n",
    "        df[campo] = df[campo].apply(lambda x: x.upper().strip() \\\n",
    "                                    .replace('\\n', '') \\\n",
    "                                    .replace('\\r', '') \\\n",
    "                                    .replace('\\t', '') \\\n",
    "                                    .replace('  ', '') \\\n",
    "                                    if isinstance(x, str) else x)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configurarLogging():\n",
    "    \"\"\"\n",
    "    Configura el logging para escribir en un archivo y en la salida estándar\n",
    "    Utiliza la ruta definida en par.ruta_log para el directorio de logs.\n",
    "    \n",
    "    Argumentos:\n",
    "        None\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        None\n",
    "    \"\"\"\n",
    "    # Configuración del logging\n",
    "    log_directory = par.ruta_log  # Usa la ruta definida en config.py\n",
    "    log_file = os.path.join(log_directory, \"cargue_datos_crudos_metas_empresas.log\")\n",
    "\n",
    "    # Crear el directorio si no existe\n",
    "    if not os.path.exists(log_directory):\n",
    "        os.makedirs(log_directory)\n",
    "\n",
    "    # Configurar el logger\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file, mode='a'),  # 'a' para modo append\n",
    "            #logging.StreamHandler()  # Para imprimir en pantalla\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fecha_inicio: 2025-01-02 17:31:37\n",
      "Fecha_fin: 02-01-2025-17-31-45\n",
      "Duracion: ['0:00:08']\n",
      "Fuentes: []\n",
      "Cantidad_registros: [163]\n",
      "Destino: ['tb_datos_crudos_metas_empresas']\n",
      "Estado: [1]\n",
      "Lugar errores:  \n",
      "Descripción errores:  \n",
      "Ejecución exitosa\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "        \"\"\"\n",
    "    Programa principal que se encarga de controlar el orden en que se debe ejecutar el procesamiento \n",
    "    \n",
    "    Argumentos:\n",
    "        None\n",
    "    Retorna: \n",
    "        None\n",
    "    Excepciones manejadas: \n",
    "        Exception as e: Captura el error en caso de que no se puedan insertar los datos en BD y genera un log localmente\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            configurarLogging()\n",
    "            id_ejecucion = generate_uuid().upper()\n",
    "            id_ejecucion_en_curso = id_ejecucion\n",
    "            \n",
    "            fecha_inicio = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            fecha_inicio_date = datetime.strptime(fecha_inicio, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "            archivos = [f for f in os.listdir(par.ruta_fuente_metas_empresas) if archivo_modificado_hoy(os.path.join(par.ruta_fuente_metas_empresas))]\n",
    "            archivo_actualizados = archivos\n",
    "\n",
    "            if par.nombre_archivo_metas_empresas in archivo_actualizados:\n",
    "                 \n",
    "                #Importar metas oficial\n",
    "                df_excel = importarMetasEmpresas(par.ruta_fuente_metas_empresas, par.hoja_calculo_metas_empresas)\n",
    "\n",
    "                #Limpieza de campos\n",
    "                df_limpiado = limpiezaCamposString(df_excel)\n",
    "\n",
    "                #Asignacion de campos faltantes\n",
    "                df_base = seleccionCamposMetasEmpresas(df_limpiado, fecha_actual, id_ejecucion_en_curso)\n",
    "\n",
    "                registros = len(df_base)\n",
    "                cantidad_registros.append(registros)\n",
    "\n",
    "                if registros > 0:\n",
    "                    df_resumen = cargueResumen(id_ejecucion, fecha_inicio_date, par.nombre_archivo_metas_empresas, registros, par.destino_metas_empresas, 1)\n",
    "                    cambioDeEstado()\n",
    "                    cargueDatosBD(df_base)\n",
    "\n",
    "                fecha_fin = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                fecha_fin_date = datetime.strptime(fecha_fin, \"%Y-%m-%d %H:%M:%S\")\n",
    "                duracion_proceso = fecha_fin_date - fecha_inicio_date\n",
    "                duracion_proceso_seg = int(duracion_proceso.total_seconds())\n",
    "                actualizarFechaFinProcesamiento(id_ejecucion, fecha_fin_date, duracion_proceso_seg)\n",
    "\n",
    "            duracion.append(str(duracion_proceso))\n",
    "            estado.append(1)\n",
    "            salidaLogMonitoreo()\n",
    "\n",
    "        except Exception as e:\n",
    "            fuentes.append(par.nombre_archivo_metas_empresas)\n",
    "            cantidad_registros.append(0)\n",
    "            estado.append(2)\n",
    "            funcion_error.append(\"__main__\")\n",
    "            descripcion_error.append(str(e)[:100])\n",
    "            salidaLogMonitoreo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
